{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic:      Prework Solutions\n",
    "#### Cohort:   03_Spring2015\n",
    "#### Date:        01-Apr-2015\n",
    "#### Author:     Reshama Shaikh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prework: Required Exercises\n",
    "\n",
    "https://github.com/datascopeanalytics/metis-data-science-bootcamp-prework/blob/master/exercises.md\n",
    "\n",
    "Source:     Think Stats (section Using the Code), there is some accompanying code and data. You can get these from the Think Stats repository.\n",
    "https://github.com/AllenDowney/ThinkStats2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Note:\n",
    "\n",
    "Step1.  Create a directory on your computer.  Below is an example:\n",
    "\n",
    "/Users/reshamashaikh/ds/metis/metisgh/\n",
    "\n",
    "Step2.  use GitHub to pull this repo to your computer\n",
    "\n",
    "git clone https://github.com/AllenDowney/ThinkStats2.git\n",
    "\n",
    "Step3.  Put your ipython notebook in this directory (that way, it can pull the needed dependencies):  \n",
    "\n",
    "/Users/reshamashaikh/ds/metis/metisgh/ThinkStats2/code/\n",
    "\n",
    "(content will match:  https://github.com/AllenDowney/ThinkStats2/tree/master/code )\n",
    "\n",
    "Step4.  Call your prework solutions notebook:  \n",
    "\n",
    "0_S_Prework_myname.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Table of Contents \n",
    "[Exercise01](#1) \n",
    "\n",
    "(Think Stats Ex 2.4) \n",
    "\n",
    "Using the variable totalwgt_lb, investigate whether first babies are lighter or heavier than others. Compute Cohen’s d to quantify the difference between the groups. How does it compare to the difference in pregnancy length?\n",
    " \n",
    "\n",
    "[Exercise02](#2)\n",
    "\n",
    "(Think Stats Ex 3.1) \n",
    "\n",
    "Something like the class size paradox appears if you survey children and ask how many children are in their family. Families with many children are more likely to appear in your sample, and families with no children have no chance to be in the sample.\n",
    "\n",
    "Use the NSFG respondent variable NUMKDHH to construct the actual distribution for the number of children under 18 in the household.\n",
    "Now compute the biased distribution we would see if we surveyed the children and asked them how many children under 18 (including themselves) are in their household.\n",
    "\n",
    "Plot the actual and biased distributions, and compute their means. As a starting place, you can use chap03ex.ipynb. This is an ipython notebook from the ThinkStats2 repository.\n",
    "\n",
    "\n",
    "[Exercise03](#3)\n",
    "\n",
    "(Think Stats Ex 4.2) \n",
    "\n",
    "The numbers generated by random.random are supposed to be uniform between 0 and 1; that is, every value in the range should have the same probability.\n",
    "Generate 1000 numbers from random.random and plot their PMF and CDF. Is the distribution uniform?\n",
    "\n",
    "\n",
    "\n",
    "[Exercise04](#4)\n",
    "\n",
    "(Think Stats Ex 7.1) \n",
    "\n",
    "Using data from the NSFG, make a scatter plot of birth weight versus mother’s age. Plot percentiles of birth weight versus mother’s age. Compute Pearson’s and Spearman’s correlations. How would you characterize the relationship between these variables?\n",
    "\n",
    "[Exercise05](#5)\n",
    "\n",
    "(Think Stats Ex 8.2)\n",
    "\n",
    "Suppose that you draw a sample with size n = 10 from an exponential distribution with λ = 2. Simulate this experiment 1000 times and plot the sampling distribution of the estimate L. Compute the standard error of the estimate and the 90% confidence interval.\n",
    "\n",
    "Repeat the experiment with a few different values of n and make a plot of standard error versus n.\n",
    "\n",
    "\n",
    "[Exercise06](#6)\n",
    "\n",
    "(Think Stats Ex 2.1 Bayes)\n",
    "\n",
    "The cookie problem is a problem discussed in sections 1.3, 2.2 and 2.3 of Think Bayes. Solve the following problem. In Section 2.3 I said that the solution to the cookie problem generalizes to the case where we draw multiple cookies with replacement. But in the more likely scenario where we eat the cookies we draw, the likelihood of each draw depends on the previous draws.\n",
    "\n",
    "Modify the solution in this chapter to handle selection without replacement. Hint: add instance variables to Cookie to represent the hypothetical state of the bowls, and modify Likelihood accordingly. You might want to define a Bowl object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='1'></a> Exercise 1 \n",
    "(Think Stats Ex 2.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Using the variable totalwgt_lb, investigate whether first babies are lighter or heavier than others. \n",
    "\n",
    "b) Compute Cohen’s d to quantify the difference between the groups. \n",
    "\n",
    "c) How does it compare to the difference in pregnancy length?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  Cohen's d is an effect size used to indicate the standardised difference between two means. It can be used, for example, to accompany reporting of t-test and ANOVA results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set working directory\n",
    "# path_data = \"/Users/reshamashaikh/_ds/metis/metisgh/ThinkStats2\"\n",
    "path_data = \"~/Documents/Metis/Programs/Homework0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Born Mean Birth Weight -  7.20109443044\n",
      "Not First Born Mean Birth Weigth -  7.32585561497\n"
     ]
    }
   ],
   "source": [
    "import nsfg\n",
    "infile = nsfg.ReadFemPreg()\n",
    "first_born = infile[infile.birthord==1]\n",
    "not_first_born = infile[infile.birthord>1]\n",
    "print \"First Born Mean Birth Weight - \", first_born.totalwgt_lb.mean()\n",
    "print \"Not First Born Mean Birth Weight - \", not_first_born.totalwgt_lb.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Question: 1a) Using the variable totalwgt_lb, investigate whether first babies are lighter or heavier than others.\n",
    "####Answer:   \n",
    "####First babies are lighter than others (7.20 vs 7.33 lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cohen d', -0.088672927072601701)\n"
     ]
    }
   ],
   "source": [
    "#b) Compute Cohen’s D to quantify the difference between the groups. \n",
    "\n",
    "# Cohen's D function\n",
    "import thinkstats2\n",
    "d = thinkstats2.CohenEffectSize(first_born.totalwgt_lb,not_first_born.totalwgt_lb)\n",
    "print('Cohen d',d)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Answer:  \n",
    "\n",
    "####Cohen's D is:  -0.0887"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) How does Cohen's D compare to the difference in pregnancy length? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cohen d', -2.2839881613276325)\n"
     ]
    }
   ],
   "source": [
    "lt_39_weeks = infile[infile.prglngth<39]\n",
    "ge_39_weeks = infile[infile.prglngth>=39]\n",
    "\n",
    "d = thinkstats2.CohenEffectSize(lt_39_weeks.prglngth,ge_39_weeks.prglngth)\n",
    "\n",
    "print('Cohen d',d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Interpretation\n",
    "This site has a good interpretation of Cohen's D, effect size:\n",
    "http://www.uccs.edu/lbecker/effect-size.html\n",
    "\n",
    "[fill in ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='2'></a> Exercise 2 \n",
    "(Think Stats Ex 3.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something like the class size paradox appears if you survey children and ask how many children are in their family. Families with many children are more likely to appear in your sample, and families with no children have no chance to be in the sample.\n",
    "\n",
    "Use the NSFG respondent variable NUMKDHH to construct the actual distribution for the number of children under 18 in the household.\n",
    "\n",
    "Now compute the biased distribution we would see if we surveyed the children and asked them how many children under 18 (including themselves) are in their household.\n",
    "\n",
    "Plot the actual and biased distributions, and compute their means. As a starting place, you can use chap03ex.ipynb. This is an ipython notebook from the ThinkStats2 repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  1.02420515504\n",
      "Biased Mean:  1.02420515504\n"
     ]
    }
   ],
   "source": [
    "import chap01soln\n",
    "resp = chap01soln.ReadFemResp()\n",
    "import thinkstats2\n",
    "pmf = thinkstats2.Pmf(resp.numkdhh)\n",
    "import thinkplot\n",
    "thinkplot.Pmf(pmf,label='numkdhh')\n",
    "thinkplot.Show()\n",
    "def BiasPMF(pmf, label=''):\n",
    "    new_pmf = pmf.Copy(label=label)\n",
    "    for x, p in pmf.Items():\n",
    "        new_pmf.Mult(x,x)\n",
    "    new_pmf.Normalize()\n",
    "    return new_pmf\n",
    "biased = BiasPmf(pmf,label='biased')\n",
    "thinkplot.PrePlot(2)\n",
    "thinkplot.Pmfs([pmf,biased])\n",
    "thinkplot.Show()\n",
    "a =  pmf.Mean()\n",
    "b =  biased.Mean()\n",
    "print (\"Mean: \",a)\n",
    "print (\"Biased Mean: \",b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='3'></a> Exercise 3 \n",
    "(Think Stats Ex 4.2)\n",
    "\n",
    "The numbers generated by random.random are supposed to be uniform between 0 and 1; that is, every value in the range should have the same probability.\n",
    "Generate 1000 numbers from random.random and plot their PMF and CDF. Is the distribution uniform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/axes/_axes.py:475: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "t = [random.random() for _ in range(1000)]\n",
    "pmf = thinkstats2.Pmf(t)\n",
    "thinkplot.Pmf(pmf, linewidth=0.1)\n",
    "thinkplot.Show()\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Answer:\n",
    "Yes, distribution looks uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='4'></a> Exercise 4 \n",
    "(Think Stats Ex 7.1)\n",
    "\n",
    "Using data from the NSFG, make a scatter plot of birth weight versus mother’s age. Plot percentiles of birth weight versus mother’s age. Compute Pearson’s and Spearman’s correlations. How would you characterize the relationship between these variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chap07scatter3.jpg\n",
      "thinkstats2 Corr 0.0688339703541\n",
      "thinkstats2 SpearmanCorr 0.0946100410966\n",
      "Writing chap07scatter1.jpg\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import nsfg\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import first\n",
    "import thinkstats2\n",
    "import thinkplot\n",
    "def ScatterPlot(ages, weights, alpha=1.0):\n",
    "    thinkplot.Scatter(ages, weights, alpha=alpha)\n",
    "    thinkplot.Config(xlabel='age (years)',\n",
    "                     ylabel='weight (lbs)',\n",
    "                     xlim=[10, 45],\n",
    "                     ylim=[0, 15],\n",
    "                     legend=False)\n",
    "\n",
    "def HexBin(ages, weights, bins=None):\n",
    "    thinkplot.HexBin(ages, weights, bins=bins)\n",
    "    thinkplot.Config(xlabel='age (years)',\n",
    "                     ylabel='weight (lbs)',\n",
    "                     legend=False)\n",
    "\n",
    "def BinnedPercentiles(df):\n",
    "    bins = np.arange(10, 48, 3)\n",
    "    indices = np.digitize(df.agepreg, bins)\n",
    "    groups = df.groupby(indices)\n",
    "\n",
    "    ages = [group.agepreg.mean() for i, group in groups][1:-1]\n",
    "    cdfs = [thinkstats2.Cdf(group.totalwgt_lb) for i, group in groups][1:-1]\n",
    "\n",
    "    thinkplot.PrePlot(3)\n",
    "    for percent in [75, 50, 25]:\n",
    "        weights = [cdf.Percentile(percent) for cdf in cdfs]\n",
    "        label = '%dth' % percent\n",
    "        thinkplot.Plot(ages, weights, label=label)\n",
    "\n",
    "    thinkplot.Save(root='chap07scatter3',\n",
    "                   formats=['jpg'],\n",
    "                   xlabel=\"mother's age (years)\",\n",
    "                   ylabel='birth weight (lbs)')\n",
    "\n",
    "def main(script):\n",
    "    thinkstats2.RandomSeed(17)\n",
    "    \n",
    "    live, firsts, others = first.MakeFrames()\n",
    "    live = live.dropna(subset=['agepreg', 'totalwgt_lb'])\n",
    "    BinnedPercentiles(live)\n",
    "\n",
    "    ages = live.agepreg\n",
    "    weights = live.totalwgt_lb\n",
    "    print('thinkstats2 Corr', thinkstats2.Corr(ages, weights))\n",
    "    print('thinkstats2 SpearmanCorr', \n",
    "          thinkstats2.SpearmanCorr(ages, weights))\n",
    "\n",
    "    ScatterPlot(ages, weights, alpha=0.1)\n",
    "    thinkplot.Save(root='chap07scatter1', \n",
    "                   legend=False,\n",
    "                   formats=['jpg'])\n",
    "# if __name__ == '__main__':\n",
    "main(sys.argv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Answer:\n",
    "For the Pearson r correlation (0.069), both variables should be normally distributed.  Other assumptions include linearity and homoscedasticity.  Linearity assumes a straight line relationship between each of the variables in the analysis and homoscedasticity assumes that data is normally distributed about the regression line.\n",
    "\n",
    "Spearman (0.95) rank correlation test does not make any assumptions about the distribution. \n",
    "\n",
    "####Conclusions:\n",
    "Data seem to be  ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='5'></a> Exercise 5\n",
    "(Think Stats Ex 8.2)\n",
    "\n",
    "Suppose that you draw a sample with size n = 10 from an exponential distribution with λ = 2. Simulate this experiment 1000 times and plot the sampling distribution of the estimate L. Compute the standard error of the estimate and the 90% confidence interval.\n",
    "\n",
    "Repeat the experiment with a few different values of n and make a plot of standard error versus n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Experiment 3\n",
      "rmse L 0.896717911545\n",
      "rmse Lm 1.24441037019\n",
      "mean error L 0.281842512904\n",
      "mean error Lm 0.294978809185\n",
      "standard error 2.37040390125\n",
      "confidence interval (85.938178105701198, 93.951543115037566)\n",
      "Writing estimation1.pdf\n",
      "Writing estimation1.eps\n",
      "Experiment 3\n",
      "rmse L 0.538114107518\n",
      "rmse Lm 0.782819364738\n",
      "mean error L 0.117244793755\n",
      "mean error Lm 0.153265170599\n",
      "standard error 1.68174720356\n",
      "confidence interval (87.095764845947798, 92.742936468004473)\n",
      "Writing estimation1.pdf\n",
      "Writing estimation1.eps\n",
      "Experiment 3\n",
      "rmse L 0.394291355192\n",
      "rmse Lm 0.575125742933\n",
      "mean error L 0.0675061290912\n",
      "mean error Lm 0.080119398328\n",
      "standard error 1.3552062097\n",
      "confidence interval (87.770149203996468, 92.275976066862356)\n",
      "Writing estimation1.pdf\n",
      "Writing estimation1.eps\n",
      "Experiment 3\n",
      "rmse L 0.339429908281\n",
      "rmse Lm 0.497960404242\n",
      "mean error L 0.0591729756462\n",
      "mean error Lm 0.0750235270488\n",
      "standard error 1.21682636422\n",
      "confidence interval (87.920244355171889, 91.969797725063898)\n",
      "Writing estimation1.pdf\n",
      "Writing estimation1.eps\n",
      "Experiment 3\n",
      "rmse L 0.299569744323\n",
      "rmse Lm 0.443144109168\n",
      "mean error L 0.0410917922103\n",
      "mean error Lm 0.0502070050598\n",
      "standard error 1.01860218053\n",
      "confidence interval (88.358483464977837, 91.681091674973615)\n",
      "Writing estimation1.pdf\n",
      "Writing estimation1.eps\n",
      "Experiment 3\n",
      "rmse L 0.26829410264\n",
      "rmse Lm 0.380136536923\n",
      "mean error L 0.0258691074103\n",
      "mean error Lm 0.0240017709988\n",
      "standard error 0.978048204161\n",
      "confidence interval (88.414488416509556, 91.654825847110089)\n",
      "Writing estimation1.pdf\n",
      "Writing estimation1.eps\n",
      "Experiment 3\n",
      "rmse L 0.242581837862\n",
      "rmse Lm 0.357352014364\n",
      "mean error L 0.0344692928151\n",
      "mean error Lm 0.0335965453614\n",
      "standard error 0.883480249262\n",
      "confidence interval (88.581168051287705, 91.475568795846002)\n",
      "Writing estimation1.pdf\n",
      "Writing estimation1.eps\n",
      "Experiment 3\n",
      "rmse L 0.225341674364\n",
      "rmse Lm 0.336892509601\n",
      "mean error L 0.015512935525\n",
      "mean error Lm 0.0319403340796\n",
      "standard error 0.827878818829\n",
      "confidence interval (88.621679483955319, 91.405233283200033)\n",
      "Writing estimation1.pdf\n",
      "Writing estimation1.eps\n",
      "Experiment 3\n",
      "rmse L 0.2164300771\n",
      "rmse Lm 0.322448126224\n",
      "mean error L 0.0169464835024\n",
      "mean error Lm 0.0393664525239\n",
      "standard error 0.770089122884\n",
      "confidence interval (88.696207514221143, 91.195749854302932)\n",
      "Writing estimation1.pdf\n",
      "Writing estimation1.eps\n",
      "Experiment 3\n",
      "rmse L 0.208183377719\n",
      "rmse Lm 0.306906198142\n",
      "mean error L 0.0266515288439\n",
      "mean error Lm 0.0415048853956\n",
      "standard error 0.778061675102\n",
      "confidence interval (88.707813065139291, 91.22670108290599)\n",
      "Writing estimation1.pdf\n",
      "Writing estimation1.eps\n",
      "[10, 20, 30, 40, 50, 60, 70, 80, 90, 100] [2.3704039012473093, 1.6817472035579264, 1.3552062097000341, 1.2168263642166524, 1.0186021805289909, 0.9780482041614247, 0.8834802492619893, 0.8278788188292714, 0.7700891228839121, 0.7780616751018985]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import thinkstats2\n",
    "import thinkplot\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def MeanError(estimates, actual):\n",
    "    \"\"\"Computes the mean error of a sequence of estimates.\n",
    "\n",
    "    estimate: sequence of numbers\n",
    "    actual: actual value\n",
    "\n",
    "    returns: float mean error\n",
    "    \"\"\"\n",
    "    errors = [estimate-actual for estimate in estimates]\n",
    "    return np.mean(errors)\n",
    "\n",
    "\n",
    "def RMSE(estimates, actual):\n",
    "    \"\"\"Computes the root mean squared error of a sequence of estimates.\n",
    "\n",
    "    estimate: sequence of numbers\n",
    "    actual: actual value\n",
    "\n",
    "    returns: float RMSE\n",
    "    \"\"\"\n",
    "    e2 = [(estimate-actual)**2 for estimate in estimates]\n",
    "    mse = np.mean(e2)\n",
    "    return math.sqrt(mse)\n",
    "\n",
    "def Estimate3(n, m):\n",
    "    \"\"\"Evaluates L and Lm as estimators of the exponential parameter.\n",
    "\n",
    "    n: sample size\n",
    "    m: number of iterations\n",
    "    \"\"\"\n",
    "    lam = 2\n",
    "\n",
    "    means = []\n",
    "    medians = []\n",
    "    for _ in range(m):\n",
    "        xs = np.random.exponential(1.0/lam, n)\n",
    "        L = 1 / np.mean(xs)\n",
    "        Lm = math.log(2) / np.median(xs)\n",
    "        means.append(L)\n",
    "        medians.append(Lm)\n",
    "\n",
    "    print('Experiment 3')\n",
    "    print('rmse L', RMSE(means, lam))\n",
    "    print('rmse Lm', RMSE(medians, lam))\n",
    "    print('mean error L', MeanError(means, lam))\n",
    "    print('mean error Lm', MeanError(medians, lam))\n",
    "\n",
    "\n",
    "def SimulateSample(mu, sigma,n, m):\n",
    "    \"\"\"Plots the sampling distribution of the sample mean.\n",
    "\n",
    "    mu: hypothetical population mean\n",
    "    sigma: hypothetical population standard deviation\n",
    "    n: sample size\n",
    "    m: number of iterations\n",
    "    \"\"\"\n",
    "    def VertLine(x, y=1):\n",
    "        thinkplot.Plot([x, x], [0, y], color='0.8', linewidth=3)\n",
    "\n",
    "    means = []\n",
    "    for _ in range(m):\n",
    "        xs = np.random.normal(mu, sigma, n)\n",
    "        xbar = np.mean(xs)\n",
    "        means.append(xbar)\n",
    "\n",
    "    stderr = RMSE(means, mu)\n",
    "    print('standard error', stderr)\n",
    "    cdf = thinkstats2.Cdf(means)\n",
    "    ci = cdf.Percentile(5), cdf.Percentile(95)\n",
    "    print('confidence interval', ci)\n",
    "    VertLine(ci[0])\n",
    "    VertLine(ci[1])\n",
    "\n",
    "    # plot the CDF\n",
    "    thinkplot.Cdf(cdf)\n",
    "    thinkplot.Save(root='estimation1',\n",
    "                   xlabel='sample mean',\n",
    "                   ylabel='CDF',\n",
    "                   title='Sampling distribution')\n",
    "    return stderr\n",
    "    \n",
    "def main():\n",
    "    thinkstats2.RandomSeed(17)\n",
    "    n = 10\n",
    "    keep_stderr = []\n",
    "    narray = []\n",
    "    i = 1\n",
    "    while i <= 10:\n",
    "        narray.append(i*10)\n",
    "        i +=1\n",
    "    print (narray)\n",
    "    for n in narray:\n",
    "        Estimate3(n,1000)\n",
    "        stderr = SimulateSample(90,7.5,n,1000)\n",
    "        n += 10\n",
    "        keep_stderr.append(stderr)\n",
    "    plt.plot(narray,keep_stderr)\n",
    "    plt.ylabel('Standard Error vs. n')\n",
    "    plt.show()\n",
    "    print (narray,keep_stderr)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "# Plot the sampling distribution of the estimate L. \n",
    "# Compute the standard error of the estimate and the 90% confidence \n",
    "# interval.Repeat the experiment with a few different values of n and \n",
    "# make a plot of standard error versus n.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='6'></a> Exercise 6\n",
    "(Think Stats Ex 2.1 Bayes)\n",
    "\n",
    "The cookie problem is a problem discussed in sections 1.3, 2.2 and 2.3 of Think Bayes. Solve the following problem. In Section 2.3 I said that the solution to the cookie problem generalizes to the case where we draw multiple cookies with replacement. But in the more likely scenario where we eat the cookies we draw, the likelihood of each draw depends on the previous draws.\n",
    "\n",
    "Modify the solution in this chapter to handle selection without replacement. Hint: add instance variables to Cookie to represent the hypothetical state of the bowls, and modify Likelihood accordingly. You might want to define a Bowl object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bowl 2': {'vanilla': 0.5, 'chocolate': 0.5}, 'Bowl 1': {'vanilla': 0.75, 'chocolate': 0.25}}\n",
      "{'vanilla': 0.5, 'chocolate': 0.5}\n",
      "0.5\n",
      "0.5\n",
      "{'vanilla': 0.75, 'chocolate': 0.25}\n",
      "0.75\n",
      "0.75\n",
      "Bowl 2 0.4\n",
      "Bowl 1 0.6\n"
     ]
    }
   ],
   "source": [
    "from thinkbayes import Pmf\n",
    "\n",
    "class Cookie(Pmf):\n",
    "    \"\"\"A map from string bowl ID to probablity.\"\"\"\n",
    "\n",
    "    def __init__(self, hypos):\n",
    "        \"\"\"Initialize self.\n",
    "\n",
    "        hypos: sequence of string bowl IDs\n",
    "        \"\"\"\n",
    "        Pmf.__init__(self)\n",
    "        for hypo in hypos:\n",
    "            self.Set(hypo, 1)\n",
    "        self.Normalize()\n",
    "\n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates the PMF with new data.\n",
    "\n",
    "        data: string cookie type\n",
    "        \"\"\"\n",
    "        for hypo in self.Values():\n",
    "            like = self.Likelihood(data, hypo)\n",
    "            print (like)\n",
    "            self.Mult(hypo, like)\n",
    "        self.Normalize()\n",
    "    \n",
    "    mixes = {\n",
    "        'Bowl 1':dict(vanilla=0.75, chocolate=0.25),\n",
    "        'Bowl 2':dict(vanilla=0.5, chocolate=0.5),\n",
    "        }\n",
    "    print (mixes)\n",
    "    def Likelihood(self, data, hypo):\n",
    "        \"\"\"The likelihood of the data under the hypothesis.\n",
    "\n",
    "        data: string cookie type\n",
    "        hypo: string bowl ID\n",
    "        \"\"\"\n",
    "        mix = self.mixes[hypo]\n",
    "        print (mix)\n",
    "        like = mix[data]\n",
    "        print (like)\n",
    "        return like\n",
    "\n",
    "def main():\n",
    "    hypos = ['Bowl 1', 'Bowl 2']\n",
    "\n",
    "    pmf = Cookie(hypos)\n",
    "\n",
    "    pmf.Update('vanilla')\n",
    "\n",
    "    for hypo, prob in pmf.Items():\n",
    "        print (hypo, prob)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
