{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic:      Prework Solutions\n",
    "#### Cohort:   03_Spring2015\n",
    "#### Date:        01-Apr-2015\n",
    "#### Author:     Reshama Shaikh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prework: Required Exercises\n",
    "\n",
    "https://github.com/datascopeanalytics/metis-data-science-bootcamp-prework/blob/master/exercises.md\n",
    "\n",
    "Source:     Think Stats (section Using the Code), there is some accompanying code and data. You can get these from the Think Stats repository.\n",
    "https://github.com/AllenDowney/ThinkStats2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Note:\n",
    "\n",
    "Step1.  Create a directory on your computer.  Below is an example:\n",
    "\n",
    "/Users/reshamashaikh/ds/metis/metisgh/\n",
    "\n",
    "Step2.  use GitHub to pull this repo to your computer\n",
    "\n",
    "git clone https://github.com/AllenDowney/ThinkStats2.git\n",
    "\n",
    "Step3.  Put your ipython notebook in this directory (that way, it can pull the needed dependencies):  \n",
    "\n",
    "/Users/reshamashaikh/ds/metis/metisgh/ThinkStats2/code/\n",
    "\n",
    "(content will match:  https://github.com/AllenDowney/ThinkStats2/tree/master/code )\n",
    "\n",
    "Step4.  Call your prework solutions notebook:  \n",
    "\n",
    "0_S_Prework_myname.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Table of Contents \n",
    "[Exercise01](#1) \n",
    "\n",
    "(Think Stats Ex 2.4) \n",
    "\n",
    "Using the variable totalwgt_lb, investigate whether first babies are lighter or heavier than others. Compute Cohen’s d to quantify the difference between the groups. How does it compare to the difference in pregnancy length?\n",
    " \n",
    "\n",
    "[Exercise02](#2)\n",
    "\n",
    "(Think Stats Ex 3.1) \n",
    "\n",
    "Something like the class size paradox appears if you survey children and ask how many children are in their family. Families with many children are more likely to appear in your sample, and families with no children have no chance to be in the sample.\n",
    "\n",
    "Use the NSFG respondent variable NUMKDHH to construct the actual distribution for the number of children under 18 in the household.\n",
    "Now compute the biased distribution we would see if we surveyed the children and asked them how many children under 18 (including themselves) are in their household.\n",
    "\n",
    "Plot the actual and biased distributions, and compute their means. As a starting place, you can use chap03ex.ipynb. This is an ipython notebook from the ThinkStats2 repository.\n",
    "\n",
    "\n",
    "[Exercise03](#3)\n",
    "\n",
    "(Think Stats Ex 4.2) \n",
    "\n",
    "The numbers generated by random.random are supposed to be uniform between 0 and 1; that is, every value in the range should have the same probability.\n",
    "Generate 1000 numbers from random.random and plot their PMF and CDF. Is the distribution uniform?\n",
    "\n",
    "\n",
    "\n",
    "[Exercise04](#4)\n",
    "\n",
    "(Think Stats Ex 7.1) \n",
    "\n",
    "Using data from the NSFG, make a scatter plot of birth weight versus mother’s age. Plot percentiles of birth weight versus mother’s age. Compute Pearson’s and Spearman’s correlations. How would you characterize the relationship between these variables?\n",
    "\n",
    "[Exercise05](#5)\n",
    "\n",
    "(Think Stats Ex 8.2)\n",
    "\n",
    "Suppose that you draw a sample with size n = 10 from an exponential distribution with λ = 2. Simulate this experiment 1000 times and plot the sampling distribution of the estimate L. Compute the standard error of the estimate and the 90% confidence interval.\n",
    "\n",
    "Repeat the experiment with a few different values of n and make a plot of standard error versus n.\n",
    "\n",
    "\n",
    "[Exercise06](#6)\n",
    "\n",
    "(Think Stats Ex 2.1 Bayes)\n",
    "\n",
    "The cookie problem is a problem discussed in sections 1.3, 2.2 and 2.3 of Think Bayes. Solve the following problem. In Section 2.3 I said that the solution to the cookie problem generalizes to the case where we draw multiple cookies with replacement. But in the more likely scenario where we eat the cookies we draw, the likelihood of each draw depends on the previous draws.\n",
    "\n",
    "Modify the solution in this chapter to handle selection without replacement. Hint: add instance variables to Cookie to represent the hypothetical state of the bowls, and modify Likelihood accordingly. You might want to define a Bowl object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='1'></a> Exercise 1 \n",
    "(Think Stats Ex 2.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Using the variable totalwgt_lb, investigate whether first babies are lighter or heavier than others. \n",
    "\n",
    "b) Compute Cohen’s d to quantify the difference between the groups. \n",
    "\n",
    "c) How does it compare to the difference in pregnancy length?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  Cohen's d is an effect size used to indicate the standardised difference between two means. It can be used, for example, to accompany reporting of t-test and ANOVA results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set working directory\n",
    "path_data = \"/Users/reshamashaikh/_ds/metis/metisgh/ThinkStats2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of df:  13593\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>pregordr</th>\n",
       "      <th>howpreg_n</th>\n",
       "      <th>howpreg_p</th>\n",
       "      <th>moscurrp</th>\n",
       "      <th>nowprgdk</th>\n",
       "      <th>pregend1</th>\n",
       "      <th>pregend2</th>\n",
       "      <th>nbrnaliv</th>\n",
       "      <th>multbrth</th>\n",
       "      <th>...</th>\n",
       "      <th>laborfor_i</th>\n",
       "      <th>religion_i</th>\n",
       "      <th>metro_i</th>\n",
       "      <th>basewgt</th>\n",
       "      <th>adj_mod_basewgt</th>\n",
       "      <th>finalwgt</th>\n",
       "      <th>secu_p</th>\n",
       "      <th>sest</th>\n",
       "      <th>cmintvw</th>\n",
       "      <th>totalwgt_lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 6</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3410.389399</td>\n",
       "      <td> 3869.349602</td>\n",
       "      <td>  6448.271112</td>\n",
       "      <td> 2</td>\n",
       "      <td>  9</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 8.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 6</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3410.389399</td>\n",
       "      <td> 3869.349602</td>\n",
       "      <td>  6448.271112</td>\n",
       "      <td> 2</td>\n",
       "      <td>  9</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 7.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 2</td>\n",
       "      <td> 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 5</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 3</td>\n",
       "      <td>  5</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 7226.301740</td>\n",
       "      <td> 8567.549110</td>\n",
       "      <td> 12999.542264</td>\n",
       "      <td> 2</td>\n",
       "      <td> 12</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 9.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 2</td>\n",
       "      <td> 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 6</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 7226.301740</td>\n",
       "      <td> 8567.549110</td>\n",
       "      <td> 12999.542264</td>\n",
       "      <td> 2</td>\n",
       "      <td> 12</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 7.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 2</td>\n",
       "      <td> 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 6</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 7226.301740</td>\n",
       "      <td> 8567.549110</td>\n",
       "      <td> 12999.542264</td>\n",
       "      <td> 2</td>\n",
       "      <td> 12</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 6.1875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 244 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   caseid  pregordr  howpreg_n  howpreg_p  moscurrp  nowprgdk  pregend1  \\\n",
       "0       1         1        NaN        NaN       NaN       NaN         6   \n",
       "1       1         2        NaN        NaN       NaN       NaN         6   \n",
       "2       2         1        NaN        NaN       NaN       NaN         5   \n",
       "3       2         2        NaN        NaN       NaN       NaN         6   \n",
       "4       2         3        NaN        NaN       NaN       NaN         6   \n",
       "\n",
       "   pregend2  nbrnaliv  multbrth    ...     laborfor_i  religion_i  metro_i  \\\n",
       "0       NaN         1       NaN    ...              0           0        0   \n",
       "1       NaN         1       NaN    ...              0           0        0   \n",
       "2       NaN         3         5    ...              0           0        0   \n",
       "3       NaN         1       NaN    ...              0           0        0   \n",
       "4       NaN         1       NaN    ...              0           0        0   \n",
       "\n",
       "       basewgt  adj_mod_basewgt      finalwgt  secu_p  sest  cmintvw  \\\n",
       "0  3410.389399      3869.349602   6448.271112       2     9      NaN   \n",
       "1  3410.389399      3869.349602   6448.271112       2     9      NaN   \n",
       "2  7226.301740      8567.549110  12999.542264       2    12      NaN   \n",
       "3  7226.301740      8567.549110  12999.542264       2    12      NaN   \n",
       "4  7226.301740      8567.549110  12999.542264       2    12      NaN   \n",
       "\n",
       "   totalwgt_lb  \n",
       "0       8.8125  \n",
       "1       7.8750  \n",
       "2       9.1250  \n",
       "3       7.0000  \n",
       "4       6.1875  \n",
       "\n",
       "[5 rows x 244 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nsfg\n",
    "df = nsfg.ReadFemPreg()\n",
    "print \"Length of df: \", len(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of firsts:  4413\n",
      "len of others:  4735\n"
     ]
    }
   ],
   "source": [
    "firsts = df[df.birthord==1]\n",
    "others = df[df.birthord>1]\n",
    "print \"len of firsts: \", len(firsts)\n",
    "print \"len of others: \", len(others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firsts total birth wt (mean):  7.20109443044\n",
      "others total birth wt (mean):  7.32585561497\n"
     ]
    }
   ],
   "source": [
    "print \"firsts total birth wt (mean): \", firsts.totalwgt_lb.mean()\n",
    "print \"others total birth wt (mean): \", others.totalwgt_lb.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Question: 1a) Using the variable totalwgt_lb, investigate whether first babies are lighter or heavier than others.\n",
    "####Answer:   \n",
    "####First babies are lighter than others (7.20 vs 7.33 lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import some packages:\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#***1.) Thinkstats exercise 2.4:\n",
    "#Using the variable totalwgt_lb, investigate whether first babies are lighter\n",
    "#or heavier than others. Compute Cohen's d to quantify the difference between \n",
    "#groups. How does it compare to the difference in pregnancy length?\n",
    "\n",
    "#Change working directory to location of ThinkStats files and import data:\n",
    "import os\n",
    "os.chdir(\"/Users/ilya/ThinkStats2/code\")\n",
    "import nsfg\n",
    "df = nsfg.ReadFemPreg()\n",
    "\n",
    "#Remove non-live births data. Outcome == 1 means live birth.\n",
    "live = df[df.outcome == 1]\n",
    "\n",
    "#Pull apart first babies data from non-first babies data:\n",
    "firsts = live[live.birthord == 1]\n",
    "others = live[live.birthord != 1]\n",
    "\n",
    "#Compute and print summary stats:\n",
    "print firsts.totalwgt_lb.mean()\n",
    "print firsts.totalwgt_lb.std()\n",
    "print others.totalwgt_lb.mean()\n",
    "print others.totalwgt_lb.std()\n",
    "\n",
    "#Check for obvious data entry mistakes (over 25lbs is reasonable cutoff):\n",
    "print firsts[firsts.totalwgt_lb > 25]\n",
    "print others[others.totalwgt_lb > 25]\n",
    "\n",
    "#Create histogram of all live birthweights:\n",
    "live.totalwgt_lb.hist()\n",
    "plt.xlabel('birthweights')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Distribution of live birthweights, n = %d' % len(live.totalwgt_lb))\n",
    "plt.show()\n",
    "\n",
    "#Compute Cohen's d to quantify the difference between groups:\n",
    "def cohens_d(series1, series2):\n",
    "    \"\"\"Computes cohen's d effect size\"\"\"\n",
    "\n",
    "    mean1, mean2 = series1.mean(), series2.mean()\n",
    "    diff = mean1 - mean2\n",
    "    var1, var2 = series1.var(), series2.var()\n",
    "    n1, n2 = len(series1), len(series2)\n",
    "\n",
    "    pooled_var = (n1 * var1 + n2 * var2) / (n1 + n2)\n",
    "    d = diff / math.sqrt(pooled_var)\n",
    "\n",
    "    return d\n",
    "\n",
    "print cohens_d(firsts.totalwgt_lb, others.totalwgt_lb)\n",
    "\n",
    "#Cohen's d is -.09. First-born babies weigh marginally less than ones born \n",
    "#later. The effect here is similar to the difference in pregnancy lengths, and \n",
    "#like the difference in pregnancy lengths, is tiny.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Answer:  \n",
    "\n",
    "####Cohen's D is:  -0.0887"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) How does Cohen's D compare to the difference in pregnancy length? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's D for birth weight is:      x.xxxx\n",
      "Cohen's D for pregnancy length is:  x.xxxx\n"
     ]
    }
   ],
   "source": [
    "print \"Cohen's D for birth weight is:      x.xxxx\"\n",
    "print \"Cohen's D for pregnancy length is:  x.xxxx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Interpretation\n",
    "This site has a good interpretation of Cohen's D, effect size:\n",
    "http://www.uccs.edu/lbecker/effect-size.html\n",
    "\n",
    "[fill in ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='2'></a> Exercise 2 \n",
    "(Think Stats Ex 3.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something like the class size paradox appears if you survey children and ask how many children are in their family. Families with many children are more likely to appear in your sample, and families with no children have no chance to be in the sample.\n",
    "\n",
    "Use the NSFG respondent variable NUMKDHH to construct the actual distribution for the number of children under 18 in the household.\n",
    "\n",
    "Now compute the biased distribution we would see if we surveyed the children and asked them how many children under 18 (including themselves) are in their household.\n",
    "\n",
    "Plot the actual and biased distributions, and compute their means. As a starting place, you can use chap03ex.ipynb. This is an ipython notebook from the ThinkStats2 repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#***2.) Thinkstats exercise 3.1:\n",
    "#Use the NSFG variable NUMKDHH to construct the actual distribution for the \n",
    "#number of children under 18 in households. Then compute the biased \n",
    "#distribution we'd see if we surveyed children and asked them how many children\n",
    "#including themselves are in the household. Plot actual and biased \n",
    "#distributions and compute their means. \n",
    "\n",
    "#import data and thinkstats package for pmfs:\n",
    "import thinkstats2 as ts\n",
    "import thinkplot as tp\n",
    "import chap01soln\n",
    "dat = chap01soln.ReadFemResp()\n",
    "\n",
    "#Make and display probability mass function:\n",
    "pmf = ts.Pmf(dat.numkdhh)\n",
    "print pmf\n",
    "tp.hist(pmf)\n",
    "plt.xlim([-.5,5.5])\n",
    "plt.xlabel('Number of children')\n",
    "plt.ylabel('Probability mass')\n",
    "plt.title('Probability mass distribution of children per household')\n",
    "plt.show()\n",
    "\n",
    "#Define function that calculates biased pmf and normalizes the probabilities:\n",
    "def BiasPmf(pmf, label = ''):\n",
    "    \"\"\"Returns the Pmf with oversampling proportional to value.\"\"\"\n",
    "\n",
    "    new_pmf = pmf.Copy(label = label)\n",
    "    \n",
    "    for x, p in pmf.Items():\n",
    "        new_pmf.Mult(x, x)\n",
    "\n",
    "    new_pmf.Normalize()\n",
    "\n",
    "    return new_pmf\n",
    "\n",
    "#Make biased pmf using above function:\n",
    "biased_pmf = BiasPmf(pmf, 'Biased_pmf')\n",
    "print biased_pmf\n",
    "\n",
    "#Plot biased and unbiased pmfs on same axes:\n",
    "tp.Hist(pmf, align = 'right', width = .35, label = 'Unbiased')\n",
    "tp.Hist(biased_pmf, align = 'left', width = .35, label = 'Biased')\n",
    "plt.xlim([-.5,5.5])\n",
    "plt.xlabel('Number of children')\n",
    "plt.ylabel('Probability mass')\n",
    "plt.title('Biased and unbiased probability mass distributions of \\nchildren \\\n",
    "per household')\n",
    "tp.Show()\n",
    "\n",
    "#Compute means of the two pmfs:\n",
    "print 'The unbiased mean children per household is %f' % pmf.Mean()\n",
    "print 'The biased mean children per household is %f'  % biased_pmf.Mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='3'></a> Exercise 3 \n",
    "(Think Stats Ex 4.2)\n",
    "\n",
    "The numbers generated by random.random are supposed to be uniform between 0 and 1; that is, every value in the range should have the same probability.\n",
    "Generate 1000 numbers from random.random and plot their PMF and CDF. Is the distribution uniform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import thinkstats2\n",
    "#Import random module and generate numbers into a list:\n",
    "import random\n",
    "numbers = [random.random() for _ in range(1000)]\n",
    "\n",
    "#Plot PMF:\n",
    "pmf = ts.Pmf(numbers)\n",
    "tp.Pmf(pmf, width = 0.01)\n",
    "plt.xlabel('Number')\n",
    "plt.ylabel('Probability mass')\n",
    "plt.title('Probability mass distribution of 1000 numbers generated with random.random')\n",
    "tp.Show()\n",
    "\n",
    "#Plot CDF:\n",
    "cdf = ts.Cdf(numbers)\n",
    "plt.title('CDF for 1000 supposedly random numbers')\n",
    "plt.xlabel('Number')\n",
    "plt.ylabel('Probability mass')\n",
    "tp.Cdf(cdf)\n",
    "tp.Show()\n",
    "\n",
    "#Yes, the distribution appears uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Answer:\n",
    "Yes, distribution looks uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='4'></a> Exercise 4 \n",
    "(Think Stats Ex 7.1)\n",
    "\n",
    "Using data from the NSFG, make a scatter plot of birth weight versus mother’s age. Plot percentiles of birth weight versus mother’s age. Compute Pearson’s and Spearman’s correlations. How would you characterize the relationship between these variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nsfg\n",
    "\n",
    "#Import and clean data\n",
    "dat = nsfg.ReadFemPreg()\n",
    "dat = dat.dropna(subset = ['totalwgt_lb'])\n",
    "\n",
    "\n",
    "#dat = dat.dropna(subset = ['totalwgt_lb', ''])\n",
    "\n",
    "#Scatterplot birthweight against mother's age:\n",
    "age, weight = dat.agepreg, dat.totalwgt_lb\n",
    "tp.Scatter(age, weight, alpha = .2)\n",
    "plt.title('Mother\\'s age vs baby birthweight')\n",
    "tp.Show(xlabel = 'Mother\\'s age', ylabel = 'Birth weight',\n",
    "    axis = [9,46,-1,16])\n",
    "\n",
    "#Hexplot birthweight against mother's age because there are so many datapoints\n",
    "#in the middle.\n",
    "tp.HexBin(age, weight)\n",
    "plt.title('Mother\\'s age vs baby birthweight')\n",
    "tp.Show(xlabel = 'Mother\\'s age', ylabel = 'Birth weight')\n",
    "\n",
    "#Bin data so that you can calculate CDF for each bin seperately:\n",
    "bins = np.arange(0, 55, 5)\n",
    "indices = np.digitize(dat.agepreg, bins)\n",
    "groups = dat.groupby(indices)\n",
    "\n",
    "#Compute mean age and CDF of birthweight:\n",
    "ages = [group.agepreg.mean() for i, group in groups][1:-1]\n",
    "cdfs = [ts.Cdf(group.totalwgt_lb) for i, group in groups]\n",
    "\n",
    "#Plot percentiles of weight vs height:\n",
    "for percent in [75, 50, 25]:\n",
    "    weights = [cdf.Percentile(percent) for cdf in cdfs[1:-1]]\n",
    "    label = '%dth' % percent\n",
    "    tp.Plot(ages, weights, label = label)\n",
    "\n",
    "plt.title('Mother\\'s age vs baby birthweight by percentile')\n",
    "tp.Show()\n",
    "\n",
    "#Compute Pearson's correlation:\n",
    "from scipy import stats\n",
    "print stats.pearsonr(age, weight)\n",
    "\n",
    "#Compute Spearman's correlation:\n",
    "print stats.spearmanr(age, weight)\n",
    "\n",
    "#Pearson's r = .07, Spearman's r = .09. Both of these are small effects. The \n",
    "#relationship is weakly positive-- as mother's age increases, so does baby\n",
    "#birthweight.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Answer:\n",
    "For the Pearson r correlation, both variables should be normally distributed.  Other assumptions include linearity and homoscedasticity.  Linearity assumes a straight line relationship between each of the variables in the analysis and homoscedasticity assumes that data is normally distributed about the regression line.\n",
    "\n",
    "Spearman rank correlation test does not make any assumptions about the distribution. \n",
    "\n",
    "####Conclusions:\n",
    "Data seem to be  ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='5'></a> Exercise 5\n",
    "(Think Stats Ex 8.2)\n",
    "\n",
    "Suppose that you draw a sample with size n = 10 from an exponential distribution with λ = 2. Simulate this experiment 1000 times and plot the sampling distribution of the estimate L. Compute the standard error of the estimate and the 90% confidence interval.\n",
    "\n",
    "Repeat the experiment with a few different values of n and make a plot of standard error versus n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import thinkstats2\n",
    "\n",
    "#Define root mean square error calculator:\n",
    "def RMSE(estimates, actual):\n",
    "    e2 = [(estimate - actual)**2 for estimate in estimates]\n",
    "    mse = np.mean(e2)\n",
    "    return math.sqrt(mse)\n",
    "\n",
    "#Define function to run simulation a bunch of times and return rmse and list of\n",
    "#estimates.\n",
    "def estimate_exp(n, m):\n",
    "    lam = 2\n",
    "    estimates = []\n",
    "    for _ in range(m):\n",
    "        xs = np.random.exponential(1.0/lam, n)\n",
    "        L = 1 / np.mean(xs)\n",
    "        estimates.append(L)\n",
    "    return estimates, RMSE(estimates, lam)\n",
    "\n",
    "#Define function that calculates percentile from percentile rank:\n",
    "def PercentileRank(values, your_value):\n",
    "    count = 0\n",
    "    for value in values:\n",
    "        if value <= your_value:\n",
    "            count += 1\n",
    "\n",
    "    return 100 * count / len(values)\n",
    "\n",
    "def Percentile(values, percentile_rank):\n",
    "    values.sort()\n",
    "    for val in values:\n",
    "        if PercentileRank(values, val) >= percentile_rank:\n",
    "            return val\n",
    "\n",
    "#Run simulation 1000 times, with 7 samples from the exp distribution per time\n",
    "#and return the estimates and root mean square error:\n",
    "estimates_list, rmse = estimate_exp(10, 1000)\n",
    "\n",
    "#Compute 95% confidence interval:\n",
    "low, high = Percentile(estimates_list, 5), Percentile(estimates_list, 95)\n",
    "\n",
    "#With sample size 10, the confidence interval is 1.28, 3.73 and the RMSE = .84.\n",
    "\n",
    "#Plot the sampling distribution of the lambda estimator L with confidence int:\n",
    "cdf = ts.Cdf(estimates_list)\n",
    "plt.title('CDF for 1000 estimates of lambda')\n",
    "plt.xlabel('Estimate')\n",
    "plt.ylabel('Probability mass')\n",
    "plt.axvline(low, color = 'red', linestyle = 'solid', alpha = .3)\n",
    "plt.axvline(high, color = 'red', linestyle = 'solid', alpha = .3)\n",
    "tp.Cdf(cdf)\n",
    "tp.Show()\n",
    "\n",
    "#Repeat experiment with values of n between 10 and 1000 that end in 0:\n",
    "rmse_list = []\n",
    "for n in range(10, 1000, 10):\n",
    "    rmse_list.append(estimate_exp(n, 1000)[1])\n",
    "\n",
    "#Plot standard error (RMSE) vs n:\n",
    "tp.Scatter(range(10,1000,10), rmse_list)\n",
    "plt.title('RMSE for different sample sizes')\n",
    "tp.Show(xlabel = 'number of items in sample', ylabel = 'RMSE', \n",
    "    axis = [0,1000,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='6'></a> Exercise 6\n",
    "(Think Stats Ex 2.1 Bayes)\n",
    "\n",
    "The cookie problem is a problem discussed in sections 1.3, 2.2 and 2.3 of Think Bayes. Solve the following problem. In Section 2.3 I said that the solution to the cookie problem generalizes to the case where we draw multiple cookies with replacement. But in the more likely scenario where we eat the cookies we draw, the likelihood of each draw depends on the previous draws.\n",
    "\n",
    "Modify the solution in this chapter to handle selection without replacement. Hint: add instance variables to Cookie to represent the hypothetical state of the bowls, and modify Likelihood accordingly. You might want to define a Bowl object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get this file from:  https://github.com/AllenDowney/ThinkBayes/blob/master/thinkbayes.py\n",
    "from thinkbayes import Pmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I can't figure out how to change the thinkbayes book's code, so I'm writing my\n",
    "#own. To test it, make an object of the bayesian_cookies class and run the last\n",
    "#function, called cookie_order() on the object, passing a list of cookies to eat\n",
    "#in the order in which they're eaten. Vanilla cookies should be called \"van\" and\n",
    "#chocolate ones should be called \"choc\". At the end, I put an example of \n",
    "#cookie_order() processing 3 cookies.\n",
    "\n",
    "class bayesian_cookies():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    bowls = {'b1': {'choc': 10, 'van': 30}, 'b2': {'choc': 20, 'van': 20}}\n",
    "\n",
    "    def p_cookie_given_bowl(self, cookie, bowl, not_cookie):\n",
    "        \"\"\"This returns the likelihood, which is the probability of the data\n",
    "        under the hypothesis\"\"\"\n",
    "\n",
    "        return self.bowls[bowl][cookie] / float(self.bowls[bowl][cookie] + \n",
    "            self.bowls[bowl][not_cookie])\n",
    "\n",
    "    p_bowl = [.5, .5] #This is the prior probability of choosing either bowl.\n",
    "\n",
    "    def p_cookie(self, cookie, not_cookie):\n",
    "        \"\"\"Returns the normalizing constant, which is the probability\n",
    "        of the data under ANY hypothesis.\"\"\"\n",
    "\n",
    "        p_v_b1 = self.bowls['b1'][cookie] / float(self.bowls['b1'][cookie] + \n",
    "            self.bowls['b1'][not_cookie])\n",
    "        p_v_b2 = self.bowls['b2'][cookie] / float(self.bowls['b2'][cookie] + \n",
    "            self.bowls['b2'][not_cookie])\n",
    "        return (p_v_b1 * self.p_bowl[0]) + (p_v_b2 * self.p_bowl[1])\n",
    "        # cookie_sum = self.bowls['b1'][cookie] + self.bowls['b2'][cookie]\n",
    "        # not_cookie_sum = self.bowls['b1'][not_cookie] + \\\n",
    "        #     self.bowls['b2'][not_cookie]\n",
    "        # return cookie_sum / float(cookie_sum + not_cookie_sum)\n",
    "\n",
    "    def bayes_theorem(self, p_b_given_a, p_a, p_b):\n",
    "        \"\"\"This defines bayes theorem, but it needs the numbers inputted\"\"\"\n",
    "\n",
    "        return (p_b_given_a * p_a) / p_b\n",
    "\n",
    "    #Probability of bowl 1 given a vanilla cookie:\n",
    "    def p_b1_given_van(self):\n",
    "        \"\"\"This passes the relevant numbers through bayes_theorem to find out\n",
    "        the prob of bowl 1 given a vanilla cookie\"\"\"\n",
    "\n",
    "        return self.bayes_theorem(self.p_cookie_given_bowl('van', 'b1', \n",
    "            'choc'), self.p_bowl[0], self.p_cookie('van', not_cookie = 'choc'))\n",
    "\n",
    "    #Prob of bowl 2 given a vanilla cookie:\n",
    "    def p_b2_given_van(self):\n",
    "        \"\"\"This passes the relevant numbers through bayes_theorem to find out\n",
    "        the prob of bowl 2 given a vanilla cookie\"\"\"\n",
    "        return 1 - self.p_b1_given_van()\n",
    "        # self.bayes_theorem(self.p_cookie_given_bowl('van', 'b2', \n",
    "        #     'choc'), self.p_bowl[1], self.p_cookie('van', not_cookie = 'choc'))\n",
    "\n",
    "    #Prob of bowl 1 given a chocolate cookie:\n",
    "    def p_b1_given_choc(self):\n",
    "        return self.bayes_theorem(self.p_cookie_given_bowl('choc', 'b1', \n",
    "            'van'), self.p_bowl[0], self.p_cookie('choc', not_cookie = 'van'))\n",
    "\n",
    "    #Prob of bowl 2 given a chocolate cookie:\n",
    "    def p_b2_given_choc(self):\n",
    "        return 1 - self.p_b1_given_choc\n",
    "\n",
    "    def eat_cookie_and_update(self, cookie_type):\n",
    "        if cookie_type == 'van':\n",
    "            # If you chose a vanilla cookie, update the number of vanilla\n",
    "            # cookies and recalculate the probability of choosing one of them,\n",
    "            # and update the probability of choosing a chocolate one\n",
    "            self.p_bowl = [self.p_b1_given_van(), self.p_b2_given_van()]\n",
    "            print \"The probabilities of a %s cookie coming from bowls 1 and 2,\\\n",
    "                respectively: %r\" % (cookie_type, self.p_bowl)\n",
    "        \n",
    "        if cookie_type == 'choc':\n",
    "            self.p_bowl = [self.p_b1_given_choc(), self.p_b2_given_choc()]\n",
    "            print \"The probabilities of a %s cookie coming from bowls 1 and 2,\\\n",
    "                respectively: %r\" % (cookie_type, self.p_bowl)\n",
    "        \n",
    "        self.bowls['b1'][cookie_type] -= 1\n",
    "        self.bowls['b2'][cookie_type] -= 1\n",
    "        print \"The bowl breakdown now is: %r\" % self.bowls\n",
    "\n",
    "    def cookie_order(self, order):\n",
    "        \"\"\"Takes a list of cookies in the order in which they're eaten and\n",
    "        returns the probabilities of each cookie coming from each of the\n",
    "        two bowls.\"\"\"\n",
    "\n",
    "        for cookie in order:\n",
    "            self.eat_cookie_and_update(cookie)\n",
    "\n",
    "eater = bayesian_cookies()\n",
    "print eater.cookie_order(['van','choc','van'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
