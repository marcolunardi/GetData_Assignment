{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic:      Prework Solutions\n",
    "#### Cohort:   03_Spring2015\n",
    "#### Date:        01-Apr-2015\n",
    "#### Author:     Reshama Shaikh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prework: Required Exercises\n",
    "\n",
    "https://github.com/datascopeanalytics/metis-data-science-bootcamp-prework/blob/master/exercises.md\n",
    "\n",
    "Source:     Think Stats (section Using the Code), there is some accompanying code and data. You can get these from the Think Stats repository.\n",
    "https://github.com/AllenDowney/ThinkStats2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Note:\n",
    "\n",
    "Step1.  Create a directory on your computer.  Below is an example:\n",
    "\n",
    "/Users/reshamashaikh/ds/metis/metisgh/\n",
    "\n",
    "Step2.  use GitHub to pull this repo to your computer\n",
    "\n",
    "git clone https://github.com/AllenDowney/ThinkStats2.git\n",
    "\n",
    "Step3.  Put your ipython notebook in this directory (that way, it can pull the needed dependencies):  \n",
    "\n",
    "/Users/reshamashaikh/ds/metis/metisgh/ThinkStats2/code/\n",
    "\n",
    "(content will match:  https://github.com/AllenDowney/ThinkStats2/tree/master/code )\n",
    "\n",
    "Step4.  Call your prework solutions notebook:  \n",
    "\n",
    "0_S_Prework_myname.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Table of Contents \n",
    "[Exercise01](#1) \n",
    "\n",
    "(Think Stats Ex 2.4) \n",
    "\n",
    "Using the variable totalwgt_lb, investigate whether first babies are lighter or heavier than others. Compute Cohen’s d to quantify the difference between the groups. How does it compare to the difference in pregnancy length?\n",
    " \n",
    "\n",
    "[Exercise02](#2)\n",
    "\n",
    "(Think Stats Ex 3.1) \n",
    "\n",
    "Something like the class size paradox appears if you survey children and ask how many children are in their family. Families with many children are more likely to appear in your sample, and families with no children have no chance to be in the sample.\n",
    "\n",
    "Use the NSFG respondent variable NUMKDHH to construct the actual distribution for the number of children under 18 in the household.\n",
    "Now compute the biased distribution we would see if we surveyed the children and asked them how many children under 18 (including themselves) are in their household.\n",
    "\n",
    "Plot the actual and biased distributions, and compute their means. As a starting place, you can use chap03ex.ipynb. This is an ipython notebook from the ThinkStats2 repository.\n",
    "\n",
    "\n",
    "[Exercise03](#3)\n",
    "\n",
    "(Think Stats Ex 4.2) \n",
    "\n",
    "The numbers generated by random.random are supposed to be uniform between 0 and 1; that is, every value in the range should have the same probability.\n",
    "Generate 1000 numbers from random.random and plot their PMF and CDF. Is the distribution uniform?\n",
    "\n",
    "\n",
    "\n",
    "[Exercise04](#4)\n",
    "\n",
    "(Think Stats Ex 7.1) \n",
    "\n",
    "Using data from the NSFG, make a scatter plot of birth weight versus mother’s age. Plot percentiles of birth weight versus mother’s age. Compute Pearson’s and Spearman’s correlations. How would you characterize the relationship between these variables?\n",
    "\n",
    "[Exercise05](#5)\n",
    "\n",
    "(Think Stats Ex 8.2)\n",
    "\n",
    "Suppose that you draw a sample with size n = 10 from an exponential distribution with λ = 2. Simulate this experiment 1000 times and plot the sampling distribution of the estimate L. Compute the standard error of the estimate and the 90% confidence interval.\n",
    "\n",
    "Repeat the experiment with a few different values of n and make a plot of standard error versus n.\n",
    "\n",
    "\n",
    "[Exercise06](#6)\n",
    "\n",
    "(Think Stats Ex 2.1 Bayes)\n",
    "\n",
    "The cookie problem is a problem discussed in sections 1.3, 2.2 and 2.3 of Think Bayes. Solve the following problem. In Section 2.3 I said that the solution to the cookie problem generalizes to the case where we draw multiple cookies with replacement. But in the more likely scenario where we eat the cookies we draw, the likelihood of each draw depends on the previous draws.\n",
    "\n",
    "Modify the solution in this chapter to handle selection without replacement. Hint: add instance variables to Cookie to represent the hypothetical state of the bowls, and modify Likelihood accordingly. You might want to define a Bowl object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='1'></a> Exercise 1 \n",
    "(Think Stats Ex 2.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Using the variable totalwgt_lb, investigate whether first babies are lighter or heavier than others. \n",
    "\n",
    "b) Compute Cohen’s d to quantify the difference between the groups. \n",
    "\n",
    "c) How does it compare to the difference in pregnancy length?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  Cohen's d is an effect size used to indicate the standardised difference between two means. It can be used, for example, to accompany reporting of t-test and ANOVA results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set working directory\n",
    "path_data = \"/Users/reshamashaikh/_ds/metis/metisgh/ThinkStats2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of df:  13593\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>pregordr</th>\n",
       "      <th>howpreg_n</th>\n",
       "      <th>howpreg_p</th>\n",
       "      <th>moscurrp</th>\n",
       "      <th>nowprgdk</th>\n",
       "      <th>pregend1</th>\n",
       "      <th>pregend2</th>\n",
       "      <th>nbrnaliv</th>\n",
       "      <th>multbrth</th>\n",
       "      <th>...</th>\n",
       "      <th>laborfor_i</th>\n",
       "      <th>religion_i</th>\n",
       "      <th>metro_i</th>\n",
       "      <th>basewgt</th>\n",
       "      <th>adj_mod_basewgt</th>\n",
       "      <th>finalwgt</th>\n",
       "      <th>secu_p</th>\n",
       "      <th>sest</th>\n",
       "      <th>cmintvw</th>\n",
       "      <th>totalwgt_lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 6</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3410.389399</td>\n",
       "      <td> 3869.349602</td>\n",
       "      <td>  6448.271112</td>\n",
       "      <td> 2</td>\n",
       "      <td>  9</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 8.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 6</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3410.389399</td>\n",
       "      <td> 3869.349602</td>\n",
       "      <td>  6448.271112</td>\n",
       "      <td> 2</td>\n",
       "      <td>  9</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 7.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 2</td>\n",
       "      <td> 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 5</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 3</td>\n",
       "      <td>  5</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 7226.301740</td>\n",
       "      <td> 8567.549110</td>\n",
       "      <td> 12999.542264</td>\n",
       "      <td> 2</td>\n",
       "      <td> 12</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 9.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 2</td>\n",
       "      <td> 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 6</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 7226.301740</td>\n",
       "      <td> 8567.549110</td>\n",
       "      <td> 12999.542264</td>\n",
       "      <td> 2</td>\n",
       "      <td> 12</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 7.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 2</td>\n",
       "      <td> 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 6</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 7226.301740</td>\n",
       "      <td> 8567.549110</td>\n",
       "      <td> 12999.542264</td>\n",
       "      <td> 2</td>\n",
       "      <td> 12</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 6.1875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 244 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   caseid  pregordr  howpreg_n  howpreg_p  moscurrp  nowprgdk  pregend1  \\\n",
       "0       1         1        NaN        NaN       NaN       NaN         6   \n",
       "1       1         2        NaN        NaN       NaN       NaN         6   \n",
       "2       2         1        NaN        NaN       NaN       NaN         5   \n",
       "3       2         2        NaN        NaN       NaN       NaN         6   \n",
       "4       2         3        NaN        NaN       NaN       NaN         6   \n",
       "\n",
       "   pregend2  nbrnaliv  multbrth    ...     laborfor_i  religion_i  metro_i  \\\n",
       "0       NaN         1       NaN    ...              0           0        0   \n",
       "1       NaN         1       NaN    ...              0           0        0   \n",
       "2       NaN         3         5    ...              0           0        0   \n",
       "3       NaN         1       NaN    ...              0           0        0   \n",
       "4       NaN         1       NaN    ...              0           0        0   \n",
       "\n",
       "       basewgt  adj_mod_basewgt      finalwgt  secu_p  sest  cmintvw  \\\n",
       "0  3410.389399      3869.349602   6448.271112       2     9      NaN   \n",
       "1  3410.389399      3869.349602   6448.271112       2     9      NaN   \n",
       "2  7226.301740      8567.549110  12999.542264       2    12      NaN   \n",
       "3  7226.301740      8567.549110  12999.542264       2    12      NaN   \n",
       "4  7226.301740      8567.549110  12999.542264       2    12      NaN   \n",
       "\n",
       "   totalwgt_lb  \n",
       "0       8.8125  \n",
       "1       7.8750  \n",
       "2       9.1250  \n",
       "3       7.0000  \n",
       "4       6.1875  \n",
       "\n",
       "[5 rows x 244 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nsfg\n",
    "df = nsfg.ReadFemPreg()\n",
    "print \"Length of df: \", len(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of firsts:  4413\n",
      "len of others:  4735\n"
     ]
    }
   ],
   "source": [
    "firsts = df[df.birthord==1]\n",
    "others = df[df.birthord>1]\n",
    "print \"len of firsts: \", len(firsts)\n",
    "print \"len of others: \", len(others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firsts total birth wt (mean):  7.20109443044\n",
      "others total birth wt (mean):  7.32585561497\n"
     ]
    }
   ],
   "source": [
    "print \"firsts total birth wt (mean): \", firsts.totalwgt_lb.mean()\n",
    "print \"others total birth wt (mean): \", others.totalwgt_lb.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Question: 1a) Using the variable totalwgt_lb, investigate whether first babies are lighter or heavier than others.\n",
    "####Answer:   \n",
    "####First babies are lighter than others (7.20 vs 7.33 lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#b) Compute Cohen’s D to quantify the difference between the groups. \n",
    "\n",
    "# Cohen's D function\n",
    "\n",
    "def CohenD(grp1, grp2):\n",
    "    print \"Computing Cohen D statistic\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Answer:  \n",
    "\n",
    "####Cohen's D is:  -0.0887"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) How does Cohen's D compare to the difference in pregnancy length? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's D for birth weight is:      x.xxxx\n",
      "Cohen's D for pregnancy length is:  x.xxxx\n"
     ]
    }
   ],
   "source": [
    "print \"Cohen's D for birth weight is:      x.xxxx\"\n",
    "print \"Cohen's D for pregnancy length is:  x.xxxx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Interpretation\n",
    "This site has a good interpretation of Cohen's D, effect size:\n",
    "http://www.uccs.edu/lbecker/effect-size.html\n",
    "\n",
    "[fill in ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='2'></a> Exercise 2 \n",
    "(Think Stats Ex 3.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something like the class size paradox appears if you survey children and ask how many children are in their family. Families with many children are more likely to appear in your sample, and families with no children have no chance to be in the sample.\n",
    "\n",
    "Use the NSFG respondent variable NUMKDHH to construct the actual distribution for the number of children under 18 in the household.\n",
    "\n",
    "Now compute the biased distribution we would see if we surveyed the children and asked them how many children under 18 (including themselves) are in their household.\n",
    "\n",
    "Plot the actual and biased distributions, and compute their means. As a starting place, you can use chap03ex.ipynb. This is an ipython notebook from the ThinkStats2 repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of families with children  1.02420515504\n",
      "Mean of all families  2.40367910066\n"
     ]
    }
   ],
   "source": [
    "import chap01soln\n",
    "import thinkstats2\n",
    "import thinkplot\n",
    "\n",
    "resp = chap01soln.ReadFemResp()\n",
    "pmf = thinkstats2.Pmf(resp.numkdhh)\n",
    "#thinkplot.Pmf(pmf, label = 'numkdhh')\n",
    "#thinkplot.Show(xlabel = 'Number of Children', ylabel = 'Frequency')\n",
    "\n",
    "def BiasPmf(pmf, label = ''):\n",
    "\tnew_pmf = pmf.Copy(label = label)\n",
    "\tfor x, p in pmf.Items():\n",
    "\t\tnew_pmf.Mult(x,x)\n",
    "\tnew_pmf.Normalize()\n",
    "\treturn new_pmf\n",
    "\n",
    "new_pmf = BiasPmf(pmf, label = \"Biased\")\n",
    "\n",
    "\n",
    "thinkplot.PrePlot(2)\n",
    "thinkplot.Pmfs([pmf, new_pmf])\n",
    "thinkplot.Show(xlabel=\"Number of Children\", ylabel=\"PMF\")\n",
    "\n",
    "print 'Mean of families with children ' ,pmf.Mean()\n",
    "print 'Mean of all families ' ,new_pmf.Mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='3'></a> Exercise 3 \n",
    "(Think Stats Ex 4.2)\n",
    "\n",
    "The numbers generated by random.random are supposed to be uniform between 0 and 1; that is, every value in the range should have the same probability.\n",
    "Generate 1000 numbers from random.random and plot their PMF and CDF. Is the distribution uniform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import thinkstats2\n",
    " \n",
    "import first\n",
    "import thinkplot\n",
    "import random\n",
    "\n",
    "\n",
    "#live, firsts, others = first.MakeFrames()\n",
    "#cdf = thinkstats2.Cdf(live.totalwgt_lb, label=\"totalwgt_lb\")\n",
    "#otherCdf = thinkstats2.Cdf(others.totalwgt_lb, label=\"totalwgt_lb\")\n",
    "#thinkplot.Cdf(cdf)\n",
    "#thinkplot.Show(xlabel=\"weeks\", ylabel=\"CDF\")\n",
    "\n",
    "#me = otherCdf.PercentileRank(8.0)\n",
    "#print \"My rank: \", me\n",
    "nums = []\n",
    "for i in range (1000):\n",
    "\tnums.append(random.random())\n",
    "\n",
    "numsCdf = thinkstats2.Cdf(nums, label = \"Random Numbers CDF\")\n",
    "thinkplot.Cdf(numsCdf)\n",
    "thinkplot.Show()\n",
    "\n",
    "numsPmf = thinkstats2.Pmf(nums, label = \"Random Numbers PMF\")\n",
    "thinkplot.Pmf(numsPmf)\n",
    "thinkplot.Show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Answer:\n",
    "Yes, distribution looks uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='4'></a> Exercise 4 \n",
    "(Think Stats Ex 7.1)\n",
    "\n",
    "Using data from the NSFG, make a scatter plot of birth weight versus mother’s age. Plot percentiles of birth weight versus mother’s age. Compute Pearson’s and Spearman’s correlations. How would you characterize the relationship between these variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson's Correlation:  0.0688339703541\n",
      "Spearman's Correlation:  0.0946100410966\n"
     ]
    }
   ],
   "source": [
    "import nsfg\n",
    "import thinkstats2\n",
    "import thinkplot\n",
    "import numpy as np \n",
    "import first\n",
    "import sys\n",
    "import math\n",
    "import pandas\t\n",
    "\n",
    "\n",
    "def Scatter(ages, weights):\n",
    "\tthinkplot.Scatter(ages, weights)\n",
    "\tthinkplot.Show( xlabel=\"Mother's Age\", \n",
    "\t\t\t   \t\tylabel=\"Birth Weight\",\n",
    "\t\t\t   \t\taxis=[10,50,0,15])\n",
    "\n",
    "def BinnedPercentiles(df):\n",
    "\t\n",
    "\tbins = np.arange(10,48,3)\n",
    "\tindices = np.digitize(df.agepreg, bins)\n",
    "\tgroups = df.groupby(indices)\n",
    "\n",
    "\tages = [group.agepreg.mean() for i, group in groups][1:-1]\n",
    "\t#print ages\n",
    "\tcdfs = [thinkstats2.Cdf(group.totalwgt_lb) for i, group in groups][1:-1]\n",
    "\tthinkplot.PrePlot(3)\n",
    "\tfor percent in [75, 50, 25]:\n",
    "\t\tweights = [cdf.Percentile(percent) for cdf in cdfs]\n",
    "\t\tlabel = '%dth' % percent\n",
    "\t\tthinkplot.Plot(ages,weights, label=label)\n",
    "\tthinkplot.show(xlabel=\"Mother's age\",\n",
    "\t\tylabel =\"Baby's Weight\",\n",
    "\t\taxis=[15,45,6.0,8.5])\n",
    "\n",
    "def covar(x,y,meanx=None,meany=None):\n",
    "\txs = np.asarray(x)\n",
    "\tys = np.asarray(y)\n",
    "\tif meanx is None:\n",
    "\t\tmeanx = np.mean(xs)\n",
    "\tif meany is None:\n",
    "\t\tmeany = np.mean(ys)\n",
    "\tcov = np.dot(xs-meanx, ys-meany) / len(xs)\n",
    "\treturn cov\n",
    "\n",
    "def PearsonsCorr(x,y):\n",
    "\tx = np.asarray(x)\n",
    "\ty = np.asarray(y)\n",
    "\tmeanx = np.mean(x)\n",
    "\tmeany = np.mean(y)\n",
    "\tvarx = np.var(x)\n",
    "\tvary = np.var(y)\n",
    "\n",
    "\tcorr = covar(x,y, meanx,meany) / math.sqrt(varx * vary)\n",
    "\treturn corr\n",
    "\n",
    "def SpearmanCorr(xs, ys):\n",
    "    xranks = pandas.Series(xs)\n",
    "    yranks = pandas.Series(ys)\n",
    "    return xs.corr(ys, method='spearman')\n",
    "\n",
    "thinkstats2.RandomSeed(17)\n",
    "live, firsts, others = first.MakeFrames()\n",
    "live = live.dropna(subset=['agepreg', 'totalwgt_lb'])\n",
    "BinnedPercentiles(live)\n",
    "\n",
    "ages = live.agepreg\n",
    "weights = live.totalwgt_lb\n",
    "\n",
    "pearson = PearsonsCorr(ages, weights)\n",
    "spearman = SpearmanCorr(ages, weights)\n",
    "print (\"Pearson's Correlation: \", pearson)\n",
    "print (\"Spearman's Correlation: \", spearman)\n",
    "\n",
    "Scatter(ages, weights)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Answer:\n",
    "For the Pearson r correlation, both variables should be normally distributed.  Other assumptions include linearity and homoscedasticity.  Linearity assumes a straight line relationship between each of the variables in the analysis and homoscedasticity assumes that data is normally distributed about the regression line.\n",
    "\n",
    "Spearman rank correlation test does not make any assumptions about the distribution. \n",
    "\n",
    "####Conclusions:\n",
    "Younger mothers <20 have lightest babies\n",
    "Weights seem to stabilize /plateau around 25-35\n",
    "Weights decrease a bit randomly at >35\n",
    "\n",
    "Technical definition of low weight baby <5.5\n",
    "\n",
    "Both Spearman & Pearson correlations are positive and small. The relationship is probably non-linear. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='5'></a> Exercise 5\n",
    "(Think Stats Ex 8.2)\n",
    "\n",
    "Suppose that you draw a sample with size n = 10 from an exponential distribution with λ = 2. Simulate this experiment 1000 times and plot the sampling distribution of the estimate L. Compute the standard error of the estimate and the 90% confidence interval.\n",
    "\n",
    "Repeat the experiment with a few different values of n and make a plot of standard error versus n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval (1.2559445099031703, 3.4818611972243843)\n",
      "rmse L 0.803524840175\n",
      "rmse Lm 1.7580807999\n",
      "mean error L 0.194322294378\n",
      "mean error Lm 0.690432044536\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import thinkstats2\n",
    "import thinkplot\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import estimation\n",
    "\n",
    "def Estimate3(n=10, m=10):\n",
    "\n",
    "\n",
    "\tdef VertLine(x, y=1):\n",
    "\t\tthinkplot.Plot([x, x], [0, y], color='0.8', linewidth=3)\n",
    "\n",
    "\tlam = 2\n",
    "\tmeans = []\n",
    "\tmedians = []\n",
    "\tfor _ in range(m):\n",
    "\t\txs = np.random.exponential(1.0/lam, n)\n",
    "\t\tL = 1 / np.mean(xs)\n",
    "\t\tLm = math.log(2) / thinkstats2.Median(xs)\n",
    "\t\tmeans.append(L)\n",
    "\t\tmedians.append(Lm)\n",
    "\n",
    "\n",
    "\tcdf = thinkstats2.MakeCdfFromList(means)\n",
    "\tci = cdf.Percentile(5), cdf.Percentile(95)\n",
    "\tprint(\"Confidence Interval\",ci)\n",
    "\tVertLine(ci[0])\n",
    "\tVertLine(ci[1])\n",
    "\tthinkplot.Cdf(cdf)\n",
    "\tthinkplot.Show()\n",
    "\t\n",
    "\n",
    "\tprint('rmse L', estimation.RMSE(means, lam))\n",
    "\tprint('rmse Lm', estimation.RMSE(medians, lam))\n",
    "\tprint('mean error L', estimation.MeanError(means, lam))\n",
    "\tprint('mean error Lm', estimation.MeanError(medians, lam))\n",
    "\n",
    "\n",
    "Estimate3(10, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='6'></a> Exercise 6\n",
    "(Think Stats Ex 2.1 Bayes)\n",
    "\n",
    "The cookie problem is a problem discussed in sections 1.3, 2.2 and 2.3 of Think Bayes. Solve the following problem. In Section 2.3 I said that the solution to the cookie problem generalizes to the case where we draw multiple cookies with replacement. But in the more likely scenario where we eat the cookies we draw, the likelihood of each draw depends on the previous draws.\n",
    "\n",
    "Modify the solution in this chapter to handle selection without replacement. Hint: add instance variables to Cookie to represent the hypothetical state of the bowls, and modify Likelihood accordingly. You might want to define a Bowl object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get this file from:  https://github.com/AllenDowney/ThinkBayes/blob/master/thinkbayes.py\n",
    "from thinkbayes import Pmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Exercise 5.1 In the BRFSS, the distribution of heights is\n",
    "roughly normal with parameters m = 178 cm and s = 7.7 cm for men,\n",
    "and m = 163 cm and s = 7.3 cm for women.\n",
    "In order to join Blue Man Group, you have to be male between 5’10” and\n",
    "6’1” (see http://bluemancasting.com). What percentage of the\n",
    "        \n",
    "min=dist.cdf(177.8)\n",
    "max=dist.cdf(185.42)\n",
    "print max-min\n",
    "0.342746837631\n",
    "Approximately 34% of the population could apply.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
