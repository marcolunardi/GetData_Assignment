{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic:      Prework Solutions\n",
    "#### Cohort:   03_Spring2015\n",
    "#### Date:        01-Apr-2015\n",
    "#### Author:     Reshama Shaikh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prework: Required Exercises\n",
    "\n",
    "https://github.com/datascopeanalytics/metis-data-science-bootcamp-prework/blob/master/exercises.md\n",
    "\n",
    "Source:     Think Stats (section Using the Code), there is some accompanying code and data. You can get these from the Think Stats repository.\n",
    "https://github.com/AllenDowney/ThinkStats2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Note:\n",
    "\n",
    "Step1.  Create a directory on your computer.  Below is an example:\n",
    "\n",
    "/Users/reshamashaikh/ds/metis/metisgh/\n",
    "\n",
    "Step2.  use GitHub to pull this repo to your computer\n",
    "\n",
    "git clone https://github.com/AllenDowney/ThinkStats2.git\n",
    "\n",
    "Step3.  Put your ipython notebook in this directory (that way, it can pull the needed dependencies):  \n",
    "\n",
    "/Users/reshamashaikh/ds/metis/metisgh/ThinkStats2/code/\n",
    "\n",
    "(content will match:  https://github.com/AllenDowney/ThinkStats2/tree/master/code )\n",
    "\n",
    "Step4.  Call your prework solutions notebook:  \n",
    "\n",
    "0_S_Prework_myname.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Table of Contents \n",
    "[Exercise01](#1) \n",
    "\n",
    "(Think Stats Ex 2.4) \n",
    "\n",
    "Using the variable totalwgt_lb, investigate whether first babies are lighter or heavier than others. Compute Cohen’s d to quantify the difference between the groups. How does it compare to the difference in pregnancy length?\n",
    " \n",
    "\n",
    "[Exercise02](#2)\n",
    "\n",
    "(Think Stats Ex 3.1) \n",
    "\n",
    "Something like the class size paradox appears if you survey children and ask how many children are in their family. Families with many children are more likely to appear in your sample, and families with no children have no chance to be in the sample.\n",
    "\n",
    "Use the NSFG respondent variable NUMKDHH to construct the actual distribution for the number of children under 18 in the household.\n",
    "Now compute the biased distribution we would see if we surveyed the children and asked them how many children under 18 (including themselves) are in their household.\n",
    "\n",
    "Plot the actual and biased distributions, and compute their means. As a starting place, you can use chap03ex.ipynb. This is an ipython notebook from the ThinkStats2 repository.\n",
    "\n",
    "\n",
    "[Exercise03](#3)\n",
    "\n",
    "(Think Stats Ex 4.2) \n",
    "\n",
    "The numbers generated by random.random are supposed to be uniform between 0 and 1; that is, every value in the range should have the same probability.\n",
    "Generate 1000 numbers from random.random and plot their PMF and CDF. Is the distribution uniform?\n",
    "\n",
    "\n",
    "\n",
    "[Exercise04](#4)\n",
    "\n",
    "(Think Stats Ex 7.1) \n",
    "\n",
    "Using data from the NSFG, make a scatter plot of birth weight versus mother’s age. Plot percentiles of birth weight versus mother’s age. Compute Pearson’s and Spearman’s correlations. How would you characterize the relationship between these variables?\n",
    "\n",
    "[Exercise05](#5)\n",
    "\n",
    "(Think Stats Ex 8.2)\n",
    "\n",
    "Suppose that you draw a sample with size n = 10 from an exponential distribution with λ = 2. Simulate this experiment 1000 times and plot the sampling distribution of the estimate L. Compute the standard error of the estimate and the 90% confidence interval.\n",
    "\n",
    "Repeat the experiment with a few different values of n and make a plot of standard error versus n.\n",
    "\n",
    "\n",
    "[Exercise06](#6)\n",
    "\n",
    "(Think Stats Ex 2.1 Bayes)\n",
    "\n",
    "The cookie problem is a problem discussed in sections 1.3, 2.2 and 2.3 of Think Bayes. Solve the following problem. In Section 2.3 I said that the solution to the cookie problem generalizes to the case where we draw multiple cookies with replacement. But in the more likely scenario where we eat the cookies we draw, the likelihood of each draw depends on the previous draws.\n",
    "\n",
    "Modify the solution in this chapter to handle selection without replacement. Hint: add instance variables to Cookie to represent the hypothetical state of the bowls, and modify Likelihood accordingly. You might want to define a Bowl object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='1'></a> Exercise 1 \n",
    "(Think Stats Ex 2.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Using the variable totalwgt_lb, investigate whether first babies are lighter or heavier than others. \n",
    "\n",
    "b) Compute Cohen’s d to quantify the difference between the groups. \n",
    "\n",
    "c) How does it compare to the difference in pregnancy length?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  Cohen's d is an effect size used to indicate the standardised difference between two means. It can be used, for example, to accompany reporting of t-test and ANOVA results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set working directory\n",
    "path_data = \"/Users/Rocket/ds3/00-prework/ThinkStats2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of df:  13593\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>pregordr</th>\n",
       "      <th>howpreg_n</th>\n",
       "      <th>howpreg_p</th>\n",
       "      <th>moscurrp</th>\n",
       "      <th>nowprgdk</th>\n",
       "      <th>pregend1</th>\n",
       "      <th>pregend2</th>\n",
       "      <th>nbrnaliv</th>\n",
       "      <th>multbrth</th>\n",
       "      <th>...</th>\n",
       "      <th>laborfor_i</th>\n",
       "      <th>religion_i</th>\n",
       "      <th>metro_i</th>\n",
       "      <th>basewgt</th>\n",
       "      <th>adj_mod_basewgt</th>\n",
       "      <th>finalwgt</th>\n",
       "      <th>secu_p</th>\n",
       "      <th>sest</th>\n",
       "      <th>cmintvw</th>\n",
       "      <th>totalwgt_lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3410.389399</td>\n",
       "      <td>3869.349602</td>\n",
       "      <td>6448.271112</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3410.389399</td>\n",
       "      <td>3869.349602</td>\n",
       "      <td>6448.271112</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7226.301740</td>\n",
       "      <td>8567.549110</td>\n",
       "      <td>12999.542264</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7226.301740</td>\n",
       "      <td>8567.549110</td>\n",
       "      <td>12999.542264</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7226.301740</td>\n",
       "      <td>8567.549110</td>\n",
       "      <td>12999.542264</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.1875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 244 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   caseid  pregordr  howpreg_n  howpreg_p  moscurrp  nowprgdk  pregend1  \\\n",
       "0       1         1        NaN        NaN       NaN       NaN         6   \n",
       "1       1         2        NaN        NaN       NaN       NaN         6   \n",
       "2       2         1        NaN        NaN       NaN       NaN         5   \n",
       "3       2         2        NaN        NaN       NaN       NaN         6   \n",
       "4       2         3        NaN        NaN       NaN       NaN         6   \n",
       "\n",
       "   pregend2  nbrnaliv  multbrth     ...       laborfor_i  religion_i  metro_i  \\\n",
       "0       NaN         1       NaN     ...                0           0        0   \n",
       "1       NaN         1       NaN     ...                0           0        0   \n",
       "2       NaN         3         5     ...                0           0        0   \n",
       "3       NaN         1       NaN     ...                0           0        0   \n",
       "4       NaN         1       NaN     ...                0           0        0   \n",
       "\n",
       "       basewgt  adj_mod_basewgt      finalwgt  secu_p  sest  cmintvw  \\\n",
       "0  3410.389399      3869.349602   6448.271112       2     9      NaN   \n",
       "1  3410.389399      3869.349602   6448.271112       2     9      NaN   \n",
       "2  7226.301740      8567.549110  12999.542264       2    12      NaN   \n",
       "3  7226.301740      8567.549110  12999.542264       2    12      NaN   \n",
       "4  7226.301740      8567.549110  12999.542264       2    12      NaN   \n",
       "\n",
       "   totalwgt_lb  \n",
       "0       8.8125  \n",
       "1       7.8750  \n",
       "2       9.1250  \n",
       "3       7.0000  \n",
       "4       6.1875  \n",
       "\n",
       "[5 rows x 244 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nsfg\n",
    "df = nsfg.ReadFemPreg()\n",
    "print \"Length of df: \", len(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of firsts:  4413\n",
      "len of others:  4735\n"
     ]
    }
   ],
   "source": [
    "firsts = df[df.birthord==1]\n",
    "others = df[df.birthord>1]\n",
    "print \"len of firsts: \", len(firsts)\n",
    "print \"len of others: \", len(others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firsts total birth wt (mean):  7.20109443044\n",
      "others total birth wt (mean):  7.32585561497\n"
     ]
    }
   ],
   "source": [
    "print \"firsts total birth wt (mean): \", firsts.totalwgt_lb.mean()\n",
    "print \"others total birth wt (mean): \", others.totalwgt_lb.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Question: 1a) Using the variable totalwgt_lb, investigate whether first babies are lighter or heavier than others.\n",
    "####Answer:   first birth is lighter than others.\n",
    "####First babies are lighter than others (7.20 vs 7.33 lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Cohen D statistic\n",
      "Computing Cohen D statistic\n",
      "-0.0886827459471\n",
      "0.0288822092882\n"
     ]
    }
   ],
   "source": [
    "#b) Compute Cohen’s D to quantify the difference between the groups. \n",
    "\n",
    "# Cohen's D function\n",
    "import numpy as np\n",
    "\n",
    "def CohenD(grp1, grp2):\n",
    "    diff = np.mean(grp1) - np.mean(grp2)\n",
    "    var1 = np.var(grp1)\n",
    "    var2 = np.var(grp2)\n",
    "    n1, n2 = len(grp1), len(grp2)\n",
    "    pooled_var = (n1 * var1 + n2 * var2) / (n1 + n2)\n",
    "    cohen = diff / np.sqrt(pooled_var)\n",
    "    \n",
    "    print \"Computing Cohen D statistic\"\n",
    "    return cohen\n",
    "\n",
    "cohen_birth_weight = CohenD(firsts.totalwgt_lb, others.totalwgt_lb)\n",
    "cohen_prglngth = CohenD(firsts.prglngth, others.prglngth)\n",
    "\n",
    "print cohen_birth_weight \n",
    "print cohen_prglngth\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Answer:  -0.0886827459471\n",
    "\n",
    "####Cohen's D is:  -0.0887"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) How does Cohen's D compare to the difference in pregnancy length? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's D for birth weight is: -0.0886827459471\n",
      "Cohen's D for pregnancy length is: 0.0288822092882\n"
     ]
    }
   ],
   "source": [
    "print \"Cohen's D for birth weight is: \" + str(cohen_birth_weight)\n",
    "print \"Cohen's D for pregnancy length is: \" + str(cohen_prglngth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Interpretation\n",
    "This site has a good interpretation of Cohen's D, effect size:\n",
    "http://www.uccs.edu/lbecker/effect-size.html\n",
    "\n",
    "[fill in ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='2'></a> Exercise 2 \n",
    "(Think Stats Ex 3.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something like the class size paradox appears if you survey children and ask how many children are in their family. Families with many children are more likely to appear in your sample, and families with no children have no chance to be in the sample.\n",
    "\n",
    "Use the NSFG respondent variable NUMKDHH to construct the actual distribution for the number of children under 18 in the household.\n",
    "\n",
    "Now compute the biased distribution we would see if we surveyed the children and asked them how many children under 18 (including themselves) are in their household.\n",
    "\n",
    "Plot the actual and biased distributions, and compute their means. As a starting place, you can use chap03ex.ipynb. This is an ipython notebook from the ThinkStats2 repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEACAYAAACuzv3DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAEolJREFUeJzt3X+w5Xdd3/Hni80yMVCryBRlsyEaskNSSpuYLFTEXRRx\n",
       "ySBRW5psSmlpaTKQsIzTqcGf2RltHZhxpDGBbjRk0BhXmyoGZYmg3pgONOzWgEh2TVaayWZjMEKk\n",
       "kBW9m7z943w3c3J7955z7j33fvdz7vMxcyfne76fc87r7mxe97Of+/2RqkKS1K5n9R1AkrQyFrkk\n",
       "Nc4il6TGWeSS1DiLXJIaZ5FLUuNGFnmSHUkOJXkgybWL7N+e5MtJ7u2+fmJ1okqSFnPaUjuTbABu\n",
       "AF4DHAX2J7mjqg4uGHpXVb1hlTJKkpYwaka+FThcVQ9W1TywF7h0kXGZejJJ0lhGFfkm4MjQ9sPd\n",
       "c8MK+I4kn0nykSTnTzOgJGlpSy6tMCjpUf4Y2FxVx5K8DvgQsGXFySRJYxlV5EeBzUPbmxnMyp9W\n",
       "VV8ZerwvyfuSPK+qvjQ8LokXdZGkZaiqJZevRxX5AeDcJGcDjwCXATuHByR5AfCXVVVJtgJZWOLj\n",
       "hjmVJdldVbv7zrFcLedvOTuYv28zkH/kJHjJIq+q40muAe4ENgA3V9XBJFd1+/cA/xJ4W5LjwDHg\n",
       "8hUnlySNbdSMnKraB+xb8Nyeocc3AjdOP5okaRye2Tm+ub4DrNBc3wFWYK7vACs013eAFZrrO8AK\n",
       "zfUdYLVlrW4skaRaXiOXpD6M050jl1YkaRSPSpuO5U52LXJJU+G/uFdmJT8MXSOXpMZZ5JLUOItc\n",
       "khpnkUuaWUkeTPI9izz/qiSH1jjLv0ty92q8t7/slDTLikUu/ldVdwMvWfs4q8MZuSQ1biZm5Fsu\n",
       "vvF9wBXAxr6zrMA8cNv9+69+e99BpBmzNckvAN/C4DLbbwP+OfArVbUZIMm7gLcC/4jBPRh+vKo+\n",
       "1O17MXAz8E8Z/H/6+1V1ebfvJcAvABcCjwE/WVX/o9v3TcAtwDbgEPB7q/UNzkSR036JwyD/FYBF\n",
       "rply1vV3HZjm+z20a9tFEwwPg/+vXsvgon4fBn4C+PiCcYeB76yqR5P8K+DWJOdU1ReAnwY+WlXb\n",
       "kjwbuAggyXOAj3Xv933Ay4CPJfnT7naYN3af+c3AtzG4+ODnl/M9jzIrSyutl/gJs/J9SKeKAm6o\n",
       "qqNV9TjwX1hwKW6Aqrq9qh7tHv8G8ACDW10C/B1wdpJNVfV3VfWJ7vnXA/+3qj5YVU9V1aeB3wTe\n",
       "2N3v+IeAn6qqv6mqzwEfZJVuizkrM/Kn3b//6uf0nWFSWy6+8Ym+M0gzbPh2lQ8BL1w4IMmbgR8G\n",
       "zu6eei7w/O7xjzCYlX8qyePAz1XVLcCLgJd3z51wGvDL3WtPW+SzV8XMFbmkU8uESyGr4awFjx8Z\n",
       "3pnkRcBNwHcDn+xuknMv3ey5W165shv7SuDjSf6IQTHfVVWvXfiB3Yz8ePd5f7ZIjqmalaUVSVpM\n",
       "gKuTbEryPODHgb0LxjyHwRLMXwHPSvIW4KVPv0HyxiRndpt/3Y19EvgdYEuSNyXZ2H1dnOQlVfUk\n",
       "g2WW3Um+rrsp/b9lvPsgT8wilzTLCvhVBkeM/DmDte+fYVDwBVBV9wE/B3wSeJRBif+vofe4CPjf\n",
       "Sb4C/Dawq6oerKqvMvgl6uUM7m/8F8DPAs/uXncNgyWaR4EPdF+rYiauRz68xtz6GnmL+SXvN7By\n",
       "J/szHOfP1hm5JDXOIpekxlnkktQ4i1ySGmeRS1LjLHJJapxndkqaipXcPFgrY5FLWjGPIe+XSyuS\n",
       "1DiLXJIaZ5FLUuMscklqnEUuSY2zyCWpcRa5JDXOIpekxlnkktQ4i1ySGjeyyJPsSHIoyQNJrl1i\n",
       "3MVJjif5oelGlCQtZckiT7IBuAHYAZwP7Exy3knGvRv4KIObmkqS1sioGflW4HB3x+h5YC9w6SLj\n",
       "3gHcDjw25XySpBFGFfkm4MjQ9sPdc09LsolBub+/e8pLWUrSGhp1GdtxSvm9wLuqqpKEJZZWkuwe\n",
       "2pyrqrkx3l+S1o0k24Htk7xmVJEfBTYPbW9mMCsf9u3A3kGH83zgdUnmq+qOhW9WVbsnCSdJ6003\n",
       "wZ07sZ3kulGvGVXkB4Bzk5wNPAJcBuxc8KHfNvSBtwAfXqzEJUmrY8kir6rjSa4B7gQ2ADdX1cEk\n",
       "V3X796xBRknSEkbe6q2q9gH7Fjy3aIFX1VumlEuSNCbP7JSkxlnkktS4kUsr0ihnXX/Xm4ArgTP6\n",
       "zrJMx4CbHtq17da+g0jL4Yxc09ByicMg+5V9h5CWyyLXNLRc4ifMwvegdcqlFU3VQ7u2XdR3hkmc\n",
       "df1dB/rOIK2UM3JJapxFLkmNs8glqXEWuSQ1ziKXpMZZ5JLUOItckhpnkUtS4yxySWqcRS5JjbPI\n",
       "JalxFrkkNc4il6TGWeSS1DiLXJIaZ5FLUuMscklqnEUuSY2zyCWpcRa5JDXOIpekxlnkktQ4i1yS\n",
       "GmeRS1LjLHJJapxFLkmNs8glqXEWuSQ1ziKXpMaNLPIkO5IcSvJAkmsX2X9pks8kuTfJ/0ny3asT\n",
       "VZK0mNOW2plkA3AD8BrgKLA/yR1VdXBo2Mer6re78f8E+C3gxauUV5K0wKgZ+VbgcFU9WFXzwF7g\n",
       "0uEBVfXE0OZzgb+abkRJ0lJGFfkm4MjQ9sPdc8+Q5AeSHAT2AbumF0+SNMqoIq9x3qSqPlRV5wHf\n",
       "D/zKilNJksa25Bo5g3XxzUPbmxnMyhdVVXcnOS3JN1XVFxfuT7J7aHOuquYmyCpJMy/JdmD7JK8Z\n",
       "VeQHgHOTnA08AlwG7FzwoecAn6+qSnIhwGIl3j2/e5JwkrTedBPcuRPbSa4b9Zoli7yqjie5BrgT\n",
       "2ADcXFUHk1zV7d8D/AvgzUnmga8Cly/3G5AkTW7UjJyq2sfgl5jDz+0Zevwe4D3TjyZJGodndkpS\n",
       "4yxySWqcRS5JjbPIJalxFrkkNc4il6TGWeSS1DiLXJIaZ5FLUuMscklqnEUuSY2zyCWpcRa5JDXO\n",
       "IpekxlnkktS4kdcjl9aLs66/60DfGZbpGHDTQ7u23dp3EPXDGbnWu2N9B5iCM4Ar+w6h/ljkWu9u\n",
       "YnbKXOuUSyta17rliGaXJBpeDtIUOSOXpMZZ5JLUOItckhpnkUtS4yxySWqcRS5JjbPIJalxFrkk\n",
       "Nc4il6TGWeSS1DiLXJIaZ5FLUuMscklqnEUuSY3zMranmC0X3/hE3xkmlUvOOZ1QbNzwpb6zSOuR\n",
       "M/JTw3zfAVasCPNPPq/vGNJ6ZJGfGm5jVspc0poba2klyQ7gvcAG4Jeq6t0L9v9r4EeAAF8B3lZV\n",
       "fzLlrDPra//mpZ8AXkqjt+vKF//mgr4zSOvZyBl5kg3ADcAO4HxgZ5LzFgz7PPBdVfUy4KcZ3AdR\n",
       "47uSRkv8GZ58qu8E0ro0ztLKVuBwVT1YVfPAXuDS4QFV9cmq+nK3eQ9w5nRjzryZKPHTHni8/eUh\n",
       "qUHjLK1sAo4MbT8MvHyJ8f8B+MhKQq1nD+3adlHfGSbV4pE20iwZp8hr3DdL8mrg3wOvXHYiSdJE\n",
       "xinyo8Dmoe3NDGblz5DkZcAvAjuq6vHF3ijJ7qHNuaqaGzupmtDo7HweuO3+/Ve/ve8gUpLtwPZJ\n",
       "XjNOkR8Azk1yNvAIcBmwc8EHnwX8JvCmqjp8sjeqqt2ThFMz5oGNfYdYgY3AFYBFrt51E9y5E9tJ\n",
       "rhv1mpG/7Kyq48A1wJ3AfcCvV9XBJFcluaob9lPANwLvT3Jvkk9NHl8Nm4Xj4Fv+QaR1bqzjyKtq\n",
       "H7BvwXN7hh6/FXjrdKOpFd2SRJOz2UaXgqRn8MxOSWqcRS5JjbPIJalxFrkkNc4il6TGWeSS1DiL\n",
       "XJIaZ5FLUuMscklqnEUuSY2zyCWpcRa5JDXOIpekxlnkktQ4i1ySGmeRS1LjLHJJapxFLkmNs8gl\n",
       "qXEWuSQ1ziKXpMZZ5JLUOItckhpnkUtS4yxySWqcRS5JjbPIJalxFrkkNc4il6TGWeSS1DiLXJIa\n",
       "Z5FLUuMscklqnEUuSY2zyCWpcRa5JDVuZJEn2ZHkUJIHkly7yP6XJPlkkq8l+U+rE1OSdDKnLbUz\n",
       "yQbgBuA1wFFgf5I7qurg0LAvAu8AfmDVUkqSTmrUjHwrcLiqHqyqeWAvcOnwgKp6rKoOAPOrlFGS\n",
       "tIQlZ+TAJuDI0PbDwMtXL46k5Trr+rsO9J1hmY4BNz20a9utfQdp1agir2l+WJLdQ5tzVTU3zfeX\n",
       "1qFjwBl9h1ihM4ArAYscSLId2D7Ja0YV+VFg89D2Zgaz8mWpqt3Lfa2kRd3EoARnocwFdBPcuRPb\n",
       "Sa4b9ZpRRX4AODfJ2cAjwGXAzpOMzRgZJU1RtxzR7Ey24eWgU8qSRV5Vx5NcA9wJbABurqqDSa7q\n",
       "9u9J8s3AfuDrgaeSvBM4v6q+usrZJUmMnpFTVfuAfQue2zP0+FGeufwiSVpDI4tcWi+2XHzjE31n\n",
       "WKZ54Lb791/99r6DqB+eoq/1bhbOf9gIXNF3CPXHItd6dxuzU+Zap1xa0brWLUc0uyTR8HKQpsgZ\n",
       "uSQ1ziKXpMZZ5JLUOItckhpnkUtS4yxySWqcRS5JjbPIJalxFrkkNc4il6TGWeSS1DivtSLplNDw\n",
       "3YJ6v3m0M3JJfTrWd4ApOHHz6N5Y5JL6dBOzU+a9cWlFUm+8efR0OCOXpMZZ5JLUOItckhpnkUtS\n",
       "4yxySWqcRS5JjbPIJalxFrkkNc4TgqQZseXiG5/oO8MyzQO33b//6rf3HaRVzsilts33HWAKNgJX\n",
       "9B2iZRa51LbbmJ0y1zK5tCI1rFuOaHZJouHloFOKM3JJapxFLkmNs8glqXGukUs6JbS4Xp5Lzjmd\n",
       "UGzc8KU+c4yckSfZkeRQkgeSXHuSMdd3+z+T5ILpx5Q0o9o/4qYI808+r88ISxZ5kg3ADcAO4Hxg\n",
       "Z5LzFoy5BHhxVZ3L4L5171+lrL1Ksr3vDCvRcv6Ws4P5R1j1wyeP/b8/W/0l5CKr/hlLGLW0shU4\n",
       "XFUPAiTZC1wKHBwa8wbggwBVdU+Sb0jygqr6wirk7dN2YK7nDCuxnXbzb6fd7GD+k1qLwyeT7K6q\n",
       "3avx3i+67qNPrsb7TmrUT6pNwJGh7Ye750aNOXPl0SRJ4xg1I68x32fhPyvGfd1U/O0l55x+4vFq\n",
       "3Qz1udvf+MKzrr/r9avx3pK0Eqk6eecmeQWwu6p2dNs/CjxVVe8eGvPfgbmq2tttHwK2LVxaSbKm\n",
       "5S5Js6KqllyDHzUjPwCcm+Rs4BHgMmDngjF3ANcAe7vi/+vF1sdHBZEkLc+SRV5Vx5NcA9wJbABu\n",
       "rqqDSa7q9u+pqo8kuSTJYeAJ4C2rnlqS9LQll1YkSae+NT1FP8kbk3wuyZNJLlzLz16ucU6IOlUl\n",
       "+UCSLyT5bN9ZliPJ5iR/2P2d+dMku/rONIkkpye5J8mnk9yX5Gf7zjSpJBuS3Jvkw31nWY4kDyb5\n",
       "k+57+FTfeSbRHcp9e5KD3d+fV5xs7Fpfa+WzwA8Cf7TGn7ss45wQdYq7hUH2Vs0DP1xV/xh4BXB1\n",
       "S3/+VfU14NVV9c+AlwGvTvKdPcea1DuB+1jjI9GmqIDtVXVBVW3tO8yE/hvwkao6j8Hfn4MnG7im\n",
       "RV5Vh6rq/rX8zBV6+oSoqpoHTpwQ1YSquht4vO8cy1VVj1bVp7vHX2XwF/mF/aaaTFUd6x4+m8Hv\n",
       "mXq9JsckkpwJXAL8Ev//IcYtaS57kn8IvKqqPgCD31dW1ZdPNt6rHy5tnBOitAa6I6cuAO7pN8lk\n",
       "kjwryaeBLwB/WFX39Z1pAj8P/Gfgqb6DrEABH09yIMl/7DvMBL4VeCzJLUn+OMkvJjnjZIOnXuRJ\n",
       "Ppbks4t8ff+0P2sNtPrPyZmS5LnA7cA7u5l5M6rqqW5p5Uzgu1q57kqS1wN/WVX30uCMdsgrq+oC\n",
       "4HUMluZe1XegMZ0GXAi8r6ouZHBE4LuWGjxVVfW9037PHh0FNg9tb2YwK9caSbIR+J/ArVX1ob7z\n",
       "LFdVfTnJ7wIX0cZ1V74DeEN3UbzTga9P8stV9eaec02kqv6i++9jSX6LwXLp3f2mGsvDwMNVtb/b\n",
       "vp0lirzPpZUWfso/fUJUkmczOCHqjp4zrRtJAtwM3FdV7+07z6SSPD/JN3SPvw74XuDeflONp6p+\n",
       "rKo2V9W3ApcDf9BaiSc5I8k/6B4/B3gtgwMuTnlV9ShwJMmW7qnXAJ872fi1PvzwB5McYXAEwu8m\n",
       "2beWnz+pqjrO4KzVOxn85v7Xq+qkvzk+1ST5NeATwJYkR5K0drLWK4E3MTja497uq6WjcL4F+INu\n",
       "jfwe4MNV9fs9Z1quFpcZXwDcPfTn/ztV9Xs9Z5rEO4BfTfIZBket/NeTDfSEIElqnEetSFLjLHJJ\n",
       "apxFLkmNs8glqXEWuSQ1ziKXpMZZ5JLUOItckhr391mYDrJwk8s7AAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121523fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1204f2b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import chap01soln\n",
    "resp = chap01soln.ReadFemResp()\n",
    "%matplotlib inline\n",
    "\n",
    "import thinkstats2\n",
    "pmf = thinkstats2.Pmf(resp.numkdhh)\n",
    "\n",
    "import thinkplot\n",
    "thinkplot.Pmfs([pmf])\n",
    "\n",
    "def BiasPmf(pmf, label=''):\n",
    "    \"\"\"Returns the Pmf with oversampling proportional to value.\n",
    "    Args:\n",
    "      pmf: Pmf object.\n",
    "      label: string label for the new Pmf.\n",
    "\n",
    "     Returns:\n",
    "       Pmf object\n",
    "    \"\"\"\n",
    "    new_pmf = pmf.Copy(label=label)\n",
    "\n",
    "    for x, p in pmf.Items():\n",
    "        new_pmf.Mult(x, x)\n",
    "        \n",
    "    new_pmf.Normalize()\n",
    "    return new_pmf\n",
    "\n",
    "bias_pmf = BiasPmf(pmf, label='biased')\n",
    "\n",
    "thinkplot.PrePlot(2)\n",
    "thinkplot.Pmfs([pmf, bias_pmf])\n",
    "thinkplot.Show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='3'></a> Exercise 3 \n",
    "(Think Stats Ex 4.2)\n",
    "\n",
    "The numbers generated by random.random are supposed to be uniform between 0 and 1; that is, every value in the range should have the same probability.\n",
    "Generate 1000 numbers from random.random and plot their PMF and CDF. Is the distribution uniform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import thinkstats2\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Answer:\n",
    "Yes, distribution looks uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='4'></a> Exercise 4 \n",
    "(Think Stats Ex 7.1)\n",
    "\n",
    "Using data from the NSFG, make a scatter plot of birth weight versus mother’s age. Plot percentiles of birth weight versus mother’s age. Compute Pearson’s and Spearman’s correlations. How would you characterize the relationship between these variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nsfg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Answer:\n",
    "For the Pearson r correlation, both variables should be normally distributed.  Other assumptions include linearity and homoscedasticity.  Linearity assumes a straight line relationship between each of the variables in the analysis and homoscedasticity assumes that data is normally distributed about the regression line.\n",
    "\n",
    "Spearman rank correlation test does not make any assumptions about the distribution. \n",
    "\n",
    "####Conclusions:\n",
    "Data seem to be  ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='5'></a> Exercise 5\n",
    "(Think Stats Ex 8.2)\n",
    "\n",
    "Suppose that you draw a sample with size n = 10 from an exponential distribution with λ = 2. Simulate this experiment 1000 times and plot the sampling distribution of the estimate L. Compute the standard error of the estimate and the 90% confidence interval.\n",
    "\n",
    "Repeat the experiment with a few different values of n and make a plot of standard error versus n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import thinkstats2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='6'></a> Exercise 6\n",
    "(Think Stats Ex 2.1 Bayes)\n",
    "\n",
    "The cookie problem is a problem discussed in sections 1.3, 2.2 and 2.3 of Think Bayes. Solve the following problem. In Section 2.3 I said that the solution to the cookie problem generalizes to the case where we draw multiple cookies with replacement. But in the more likely scenario where we eat the cookies we draw, the likelihood of each draw depends on the previous draws.\n",
    "\n",
    "Modify the solution in this chapter to handle selection without replacement. Hint: add instance variables to Cookie to represent the hypothetical state of the bowls, and modify Likelihood accordingly. You might want to define a Bowl object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get this file from:  https://github.com/AllenDowney/ThinkBayes/blob/master/thinkbayes.py\n",
    "from thinkbayes import Pmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
