{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Web Scraping 1: BeautifulSoup\n",
    "\n",
    "[BeautifulSoup documentation](http://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "\n",
    "For Project Luther, we will be scraping information about movies from the internet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, an HTML refresher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HTML is the basic language used to create a web page. \n",
    "# It tells the web browser what text/media to display, where to display it, and how to display it (style)\n",
    "# HTML is very structured/hirarchical. \n",
    "# Every page is made up of discrete \"elements\"\n",
    "# Elements are labeled with \"tags\"\n",
    "\n",
    "# For example:\n",
    "#      <p>You are beginning to learn HTML.</p>\n",
    "\n",
    "# A start tag also often contains \"attributes\" with info about the element.\n",
    "# Attributes usually have a name and value\n",
    "# Example:\n",
    "#       <p class=\"my_red_sentences\">You are beginning to learn HTML.</p>\n",
    "\n",
    "\n",
    "# <html> \n",
    "#   <head> </head>\n",
    "#   <body>\n",
    "#      <p class=\"red\">You are beginning to learn HTML.</p>\n",
    "#      <h1> This is a header </h1>\n",
    "#      <a href=\"www.google.com\"> Some link </a>\n",
    "#   </body>\n",
    "# </html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Get the HTML from a page and convert to a BeautifulSoup object\n",
    "\n",
    "we'll start by scraping some information from [this page](http://boxofficemojo.com/movies/?id=biglebowski.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "\n",
    "## students might have to: sudo pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'http://boxofficemojo.com/movies/?id=biglebowski.htm'\n",
    "\n",
    "page = urllib2.urlopen(url)\n",
    "soup = BeautifulSoup(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print soup\n",
    "#print soup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##soup.find() \n",
    "soup.find() is the most common function we will use from this package.  \n",
    "Let's try out some common variations of soup.find() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"/goto.php?a=5\" target=\"4\"><font face=\"Verdana\" size=\"3\"><b>'Furious 7' hits $800 million worldwide... &gt;</b></font><br/></a>\n",
      "<a href=\"/goto.php?a=5\" target=\"4\">\n",
      " <font face=\"Verdana\" size=\"3\">\n",
      "  <b>\n",
      "   'Furious 7' hits $800 million worldwide... &gt;\n",
      "  </b>\n",
      " </font>\n",
      " <br/>\n",
      "</a>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# soup.find() returns the first matched tag it finds. It searches the entire tree.\n",
    "# search for a type of tag by using the tag as a string (like 'body','div','p','a') as an argument.\n",
    "print soup.find('a')\n",
    "\n",
    "#Equivalently:\n",
    "#print soup.a\n",
    "print soup.a.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/goto.php?a=5'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soup.find_all() returns a list of all matches\n",
    "#for link in soup.find_all('a'): \n",
    "#    print link\n",
    "\n",
    "# retrieve the url from an anchor tag \n",
    "soup.find('a')['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<td width=\"40%\"><b>Domestic:</b></td>, <td align=\"right\" width=\"35%\">Â <b>$17,451,873</b></td>]\n"
     ]
    }
   ],
   "source": [
    "# you can match on an attribute like an id or class. \n",
    "# With your web browser (like Chrome), you can show what \n",
    "# the 'mp_box_content' classes look like on the webpage with Inspect Element\n",
    "\n",
    "#for element in soup.find_all(class_='mp_box_content'):\n",
    "#    print element, '\\n'\n",
    "\n",
    "#finding all the columns in the first mp_box_content table. Chaining find/find_all\n",
    "print soup.find(class_='mp_box_content').find_all('td')\n",
    "\n",
    "# find with an id. ID is unique.\n",
    "# print soup.find(id='hp_footer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Do we need to take a break?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Consistency\n",
    "Web scraping is made simple by the consistent format of information among like pages of a website. \n",
    "\n",
    "###Items to scrape for each movie:\n",
    "* movie title\n",
    "* total domestic gross\n",
    "* release date\n",
    "* runtime\n",
    "* rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Big Lebowski (1998) - Box Office Mojo</title>\n",
      "The Big Lebowski (1998) - Box Office Mojo\n",
      "[u'The Big Lebowski ', u'1998) - Box Office Mojo']\n",
      "The Big Lebowski\n"
     ]
    }
   ],
   "source": [
    "# Movie Title\n",
    "print soup.find('title')\n",
    "title_string = soup.find('title').text\n",
    "print title_string\n",
    "print title_string.split('(')\n",
    "title = title_string.split('(')[0].strip()\n",
    "print title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domestic Total Gross: \n",
      "None\n",
      "Domestic Total Gross: \n",
      "<b>$17,451,873</b>\n",
      "17451873\n"
     ]
    }
   ],
   "source": [
    "# Domestic Total Gross \n",
    "## This turns the text from an exact text match into a regex.\n",
    "print soup.find(text=\"Domestic Total Gross: \")\n",
    "## text does an exact match search!\n",
    "print soup.find(text=\"Domestic Total Gross\")\n",
    "\n",
    "import re\n",
    "dtg_string = soup.find(text=re.compile('Domestic Total'))\n",
    "print dtg_string\n",
    "print dtg_string.findNextSibling()\n",
    "dtg = dtg_string.findNextSibling().text\n",
    "\n",
    "dtg = dtg.replace('$','').replace(',','')\n",
    "domestic_total_gross = int(dtg)\n",
    "\n",
    "print domestic_total_gross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###We can actually do several of these using the text matching method, so let's make a function for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_movie_value(soup,field_name):\n",
    "    '''\n",
    "    takes a string attribute of a movie on the page and \n",
    "    returns the string in the next sibling object (the value for that attribute)\n",
    "    '''\n",
    "    obj = soup.find(text=re.compile(field_name))\n",
    "    if not obj: \n",
    "        return None\n",
    "    \n",
    "    # this works for most of the values\n",
    "    next_sibling = obj.findNextSibling()\n",
    "    if next_sibling:\n",
    "        return next_sibling.text\n",
    "        \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$17,451,873\n",
      "1 hrs. 57 min.\n",
      "R\n"
     ]
    }
   ],
   "source": [
    "#domestic total gross\n",
    "dtg = get_movie_value(soup,'Domestic Total')\n",
    "print dtg\n",
    "\n",
    "#runtime\n",
    "runtime = get_movie_value(soup,'Runtime')\n",
    "print runtime\n",
    "\n",
    "#rating\n",
    "rating = get_movie_value(soup,'MPAA Rating')\n",
    "print rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Break time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###we need a few helper methods to parse the strings we've gotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dateutil.parser\n",
    "\n",
    "def to_date(datestring):\n",
    "    date = dateutil.parser.parse(datestring)\n",
    "    return date\n",
    "\n",
    "def money_to_int(moneystring):\n",
    "    moneystring = moneystring.replace('$','').replace(',','')\n",
    "    return int(moneystring)\n",
    "\n",
    "def runtime_to_minutes(runtimestring):\n",
    "    runtime = runtimestring.split() #default is whitespace\n",
    "    try:\n",
    "        minutes = int(runtime[0])*60 + int(runtime[2])\n",
    "        return minutes\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "March 6, 1998\n",
      "[{'domestic total gross': 17451873,\n",
      "  'movie title': u'The Big Lebowski',\n",
      "  'rating': u'R',\n",
      "  'release date': datetime.datetime(1998, 3, 6, 0, 0),\n",
      "  'runtime (mins)': 117}]\n"
     ]
    }
   ],
   "source": [
    "#let's get these again and format them all in one swoop\n",
    "from pprint import pprint\n",
    "\n",
    "raw_release_date = get_movie_value(soup,'Release Date')\n",
    "print raw_release_date\n",
    "release_date = to_date(raw_release_date)\n",
    "\n",
    "raw_domestic_total_gross = get_movie_value(soup,'Domestic Total')\n",
    "domestic_total_gross = money_to_int(raw_domestic_total_gross)\n",
    "\n",
    "raw_runtime = get_movie_value(soup,'Runtime')\n",
    "runtime = runtime_to_minutes(raw_runtime)\n",
    "\n",
    "headers = ['movie title','domestic total gross','release date','runtime (mins)','rating']\n",
    "\n",
    "movie_data = []\n",
    "movie_dict = dict(zip(headers,[title,\n",
    "                               domestic_total_gross,\n",
    "                               release_date,\n",
    "                               runtime,\n",
    "                               rating]))\n",
    "#print movie_dict\n",
    "movie_data.append(movie_dict)\n",
    "\n",
    "pprint(movie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 1), ('b', 2), ('c', 3)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2, 'c': 3}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## optional extra about zip fnc\n",
    "a = ['a','b','c']\n",
    "b = [1,2,3]\n",
    "print zip(a,b)\n",
    "dict(zip(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Regexes (Regular Expressions)\n",
    "## We strongly enourage you to read up and practice regular expressions. It's in Dive Into Python, Chapter 7.\n",
    "## http://www.diveintopython.net/regular_expressions/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
